---
title: ''
output:
  html_document: default
  html_notebook: default
---

# Import libraries

```{r, warning=F, message=F}
library(ggplot2)
library(lme4)
library(lmerTest)
library(tidyr)
library(dplyr)
library(qdap)
library(stringr)
library(knitr)
library(xtable)
library(readr)
```

# Pre-processing human data

## Imports 

First, we read in the different data tables and align the fields.

```{r}
msgs = read_csv("./humanOutput/rawCorpus/messages.csv") %>%
  rename(msgTime = time, 
         role = sender)

clks = read.csv("./humanOutput/rawCorpus/clicks.csv") %>%
  mutate(condition = factor(condition, levels = c("closer", "further", "equal"), 
                            labels = c("close", "split", "far"))) %>%
  rename(clkTime = time)

subjInfo = read.csv("./humanOutput/rawCorpus/subjectInfo.csv") %>%
  rename(gameid = gameID) %>%
  select(-workerid)

workerIds = read.csv("./humanOutput/rawCorpus/uniqueWorkerIDs.csv") 

rawAggregated <- clks %>% 
  left_join(msgs, by = c("gameid", "roundNum")) %>%
  left_join(subjInfo, by = c("gameid", "role")) %>%
  left_join(workerIds, by = c("gameid", "role"))
```

## Exclusions 

Next, create our exclusion criterion (remove games where participants were confused, spoke english as a second language, or didn't complete all trials) and create a list of the games that satisfy it. 

Note that (1) by using subjInfo to create lists of bad IDs, we can exclude a game even if it was the *listener* who isn't a native english speaker and they didn't talk at all and (2) this *doesn't* exclude NAs. 

```{r}
nonNativeSpeakerIDs <- unique((subjInfo %>% filter(nativeEnglish != "yes"))$gameid)
confusedIDs <- unique((subjInfo %>% filter(confused != "yes"))$gameid)
incompleteIDs <- unique((rawAggregated %>% 
                           group_by(gameid) %>% 
                           filter(length(unique(roundNum)) != 50))$gameid)
badGames <- union(incompleteIDs, union(nonNativeSpeakerIDs, confusedIDs))
```

## Create filtered data frame

Now we join the data frames together and do some pre-computation of some features we're going to use. Note: there's a bunch of additional pre-processing that it'd be nice to do but seems inessential. For instance, it would be nice to strip all the meta-commentary (e.g. "oops" after missing, complaining about task, etc.)

```{r}
prefilter <- clks %>%
  left_join(msgs, by = c("gameid", "roundNum")) %>%
  left_join(workerIds, by = c("gameid", "role")) %>% 
  filter(!(gameid %in% badGames)) %>%
  mutate(numOutcome = ifelse(outcome == "true", 1, 0)) %>%
  mutate(numRawWords = word_count(contents)) %>%
  mutate(numRawChars = character_count(contents)) %>%
  filter(numRawWords > 0) # Get rid of NAs from empty string messages

combined_human <- prefilter %>%
  filter(numRawWords < mean(numRawWords) + 4*sd(numRawWords)) %>%
  mutate(strippedContents = str_replace_all(contents, "[^[:alnum:][:space:]']",' ')) %>%
  do(mutate(., cleanMsg = rm_stopwords(.$strippedContents, tm::stopwords("english"), 
                                       separate = F))) %>%
  mutate(numCleanChars = character_count(cleanMsg)) %>%
  mutate(numCleanWords = word_count(cleanMsg)) %>%
  mutate(source = 'human') %>%
  select(-strippedContents, -cleanMsg)

write_csv(combined_human, path = "humanOutput/filteredCorpus.csv")
```

```{r}
paste(c(length(unique(combined_human$gameid)), 
        "complete games w/ native english speakers out of a total of",
        length(unique(rawAggregated$gameid)),
        "games with at least one message"), collapse = " ")
```

```{r}
paste(c("# messages excluded for being too long: ",
        length(prefilter$contents) - length(combined_human$contents)), collapse = '')
paste(c("which, in terms of proportion, is : ", round((length(prefilter$contents) - length(combined_human$contents))
        /length(prefilter$contents), 3)), collapse = '')

paste0(c("examples of long utterance... :" ,
       head(setdiff(prefilter$contents, combined_human$contents))))
```

## Meta-data analyses

Get histogram of # games per turker

```{r}
numGamesPlayed <- workerIds %>% 
  group_by(workerid_uniq) %>% 
  summarize(numGames = length(gameid)) %>%
  group_by(numGames) %>%
  summarize(numParticipants = length(workerid_uniq))

# ggplot(numGamesPlayed, aes(x = numGames, y = numParticipants)) + 
#   geom_bar(stat = 'identity')

paste(c("modal number is", 
         numGamesPlayed$numGames[[which.max(numGamesPlayed$numParticipants)]],
         "game, totaling", 
         round(100 * max(numGamesPlayed$numParticipants)/sum(numGamesPlayed$numParticipants)),
        "% of participants"), collapse = " ")
```

Apparently there was a bug affecting a small number of turkers where both players were assigned to the same role. Since this seemed to cause their game to terminate early, all of these players were excluded under pre-set criteria.

```{r}
workerIds %>% group_by(gameid, role) %>% tally() %>% filter(n > 1)
```

Note that the games in the raw messages dataset are a superset of the games in the raw clicks dataset; this is because a number of games ended with a player disconnecting before ever clicking, even though some messages were sent.

```{r}
setdiff(unique(msgs$gameid), unique(clks$gameid))
```

Why are some of the unique worker ids in the filtered corpus NAs? Because there was a small number of turkers that completed the task but did not submit their HIT. We're including this data even though we don't have complete subject info on them. 

```{r}
paste(c(length(unique((combined_human %>% filter(is.na(workerid_uniq)))$gameid)),
        "games where we don't have complete subject info on speaker"), collapse = ' ')
```

Check total number of each kind of condition in the final corpus:

```{r}
combined_human %>% group_by(gameid, roundNum) %>% 
  filter(row_number()==1) %>% # limit to one row per round
  group_by(condition) %>% tally()
```

Speakers sometimes sent more than one message per round... 

```{r}
msgsPerRound <- combined_human %>% 
  filter(role == "speaker") %>% 
  group_by(gameid, roundNum) %>% 
  summarize(numMessages = length(contents)) %>% 
  group_by(numMessages) %>% 
  summarize(numRounds = length(roundNum))

paste(c("modal number is", 
         msgsPerRound$numMessages[[which.max(msgsPerRound$numRounds)]],
         "message, totaling", 
         round(100 * max(msgsPerRound$numRounds)/sum(msgsPerRound$numRounds)),
        "% of rounds"), collapse = " ")

paste(c("total of", length((combined_human %>% filter(role == "speaker"))$gameid), "utterances in",
        sum(msgsPerRound$numRounds), "rounds"),
      collapse = ' ')
```

# Preprocessing model data

Template for pulling in listener & speaker

```{r}
makeModelDF <- function(listenerOutput, speakerOutput, sourceLabel) {
  robo_msgs = read.csv(speakerOutput) %>%
    select(gameid, roundNum, msgTime, role, contents) %>%
    mutate(role = "speaker") %>%
    mutate(contents = trimws(as.character(contents)))

  robo_clks = read.csv(listenerOutput) %>%
    select(-msgTime, -role, -contents, -numOutcome)

  combined_model <- robo_clks %>% 
    left_join(robo_msgs, by = c("gameid", "roundNum")) %>%
    mutate(numOutcome = ifelse(outcome == "true", 1, 0)) %>%
    mutate(numRawWords = word_count(contents)) %>%
    mutate(numRawChars = character_count(contents)) %>%
    filter(numRawWords > 0) %>% # Get rid of NAs from empty string messages 
    filter(numRawWords < mean(numRawWords) + 4*sd(numRawWords)) %>% # Get rid of longest outliers
    mutate(strippedContents = str_replace_all(contents, "[^[:alnum:][:space:]']",' ')) %>%
    do(mutate(., cleanMsg = rm_stopwords(.$strippedContents, tm::stopwords("english"), 
                                         separate = F))) %>%
    mutate(numCleanWords = word_count(cleanMsg)) %>%
    mutate(numCleanChars = character_count(cleanMsg)) %>%
    mutate(source = sourceLabel) %>%
    mutate(workerid_uniq = NA) %>%
    select(-strippedContents, -cleanMsg)
  
  return(combined_model)
}
```

Next, pull in S2/L2 model output

```{r}
literalModel <- makeModelDF(
  "./modelOutput/listener_filtered_l0.csv",
  "./modelOutput/speaker_filtered_s0.csv",
  "literal"
)
     
pragmaticModel <- makeModelDF(
  "./modelOutput/listener_filtered_le.csv",
  "./modelOutput/speaker_filtered_sl_sampled.csv",
  "pragmatic"
)

combined = rbind(combined_human, literalModel, pragmaticModel) 
```

# Listener analysis: Do people make more mistakes on harder trials?

### Setup 

Define some helper functions...

```{r}
library(bootstrap)

## for bootstrapping 95% confidence intervals
## by Michael Frank: https://github.com/langcog/pragmods/blob/master/analysis/useful_dplyr.R
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
  mean(x,na.rm=na.rm) - quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)}
ci.high <- function(x,na.rm=T) {
  quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) - mean(x,na.rm=na.rm)}

listener_df = combined %>% 
  group_by(gameid, roundNum, source) %>% 
  filter(row_number()==1) %>% # limit to one row per round
  ungroup()
```

### Compute overall human error rate 

```{r}
listener_df %>% filter(source == "human") %>% summarize(errorRate = mean(numOutcome))
```

### Look at model differences across conditions

```{r}
cairo_pdf("../writing/2016/figures/changedByCondition.pdf", width=6,height=3)
dodge <- position_dodge(width=0.9)
listener_df %>% 
  filter(source != 'human') %>%
  select(gameid, roundNum, source, numOutcome, condition) %>%
  spread(source, numOutcome) %>%
  filter(!is.na(literal) & !is.na(pragmatic)) %>% # NAs come from diff exclusions
  mutate(improvement = ifelse(!literal & pragmatic, 100, 0),
         decline = ifelse(literal & !pragmatic, 100, 0)) %>%
#         nochange = ifelse(literal == pragmatic, 1, 0)) %>%
  group_by(condition) %>%
  summarize("improvedMS" = mean(improvement), 
            "declinedMS" = mean(decline),
            # "se" = 50 * sqrt(1/length(improvement)),
            "improvedLS" = ci.low(improvement),
            "declinedLS" = ci.low(decline),
            "improvedHS" = ci.high(improvement),
            "declinedHS" = ci.high(decline)
            # "nochangeM" = mean(nochange)
            ) %>%
  gather(key, count, ends_with("S")) %>%
  mutate(key = gsub(".$", "", key)) %>%
  extract(key, c("change", "statistic"), "(.*)(.)") %>%
  spread(statistic, count) %>%
  ggplot(aes(x = condition, y = M, fill = change)) +
    geom_bar(stat = 'identity', position = dodge) +
    geom_errorbar(aes(ymax = M + H, ymin = M - L),
                  position=dodge, width=0.25) +
    theme_bw() +
    ylab("% of trials changed, L??? ??? L???")
dev.off()
```

### Make human vs. model table

```{r}
listenerSummary <- listener_df %>% group_by(condition, source) %>%
  summarize(percentCorrect = mean(numOutcome), 
            low = ci.low(numOutcome),
            high = ci.high(numOutcome)) 
print(listenerSummary)
listenerSummary %>%
  select(-low, -high) %>%
  spread(condition, percentCorrect)
```

### Make bar plot

```{r}
cairo_pdf("../writing/2016/figures/listenerAccuracy.pdf", width = 6, height = 3)

ordering <- function(source) {
  match(source, c("literal", "pragmatic", "human"))
}

dodge <- position_dodge(width=0.9)
listenerSummary %>%
  mutate(sourceNum = paste(ordering(source), source)) %>%
  ggplot(aes(x = condition, y = percentCorrect * 100.0, fill = sourceNum)) +
    geom_bar(stat = "identity", position = "dodge") +
    geom_errorbar(aes(ymax = (percentCorrect + high) * 100.0, ymin = (percentCorrect - low) * 100.0),
                  position=dodge, width=0.25) + 
    coord_cartesian(ylim = c(70.0, 100.0)) +
    ylab("% correct") +
    scale_fill_discrete("agent", labels=c("literal (L???)", "pragmatic (L???)", "human")) +
    theme_bw()
dev.off()
```

# Generate latex table for TACL paper:

Note that taggedColorMsgs2.csv is created in tagPOS.ipynb & informativities.csv is created in wordnet.ipynb

We're going to run both human and model output through a pipeline to get a table with the different conditions as columns and different metrics as rows... 

```{r}
taggedDF = read_csv("./taggedColorMsgs.csv") %>% 
  mutate(contents = trimws(as.character(contents))) %>%
  select(gameid, roundNum, contents, numSuper, numComp)

informativityDF = read_csv("informativities.csv") %>%
  mutate(contents = trimws(as.character(contents))) %>%
  select(gameid, roundNum, source, contents, specificity)

# TODO: present se in table (e.g. in parens after mean)
speakerStats = combined %>% 
  filter(role == 'speaker') %>%
  left_join(taggedDF) %>%
  left_join(informativityDF) %>%
  filter(numRawWords > 0) %>% # Get rid of NAs from empty strings
  mutate(condition = relevel(condition, ref = 'far')) %>%
  mutate(comparativesIndicator = numComp > 0) %>%
  mutate(superlativesIndicator = numSuper > 0) %>%
  mutate(negativesIndicator = str_count(contents, fixed("not ")) > 0) %>%
  mutate(specificityIndicator = specificity > 7) %>%
  select(gameid, roundNum, condition, source, numRawWords, numRawChars,
         comparativesIndicator, superlativesIndicator, negativesIndicator, specificityIndicator)

resultTable = speakerStats %>%
   group_by(gameid, condition, source) %>%
   summarise(numWordsPerMessage = mean(numRawWords),
             numCharsPerMessage = mean(numRawChars),
             comparativesRate = mean(comparativesIndicator),
             superlativesRate = mean(superlativesIndicator),
             negativesRate = mean(negativesIndicator),
             specificityRate = mean(specificityIndicator, na.rm = T)) %>%
   group_by(condition, source) %>% 
   summarize("# WordsM" = mean(numWordsPerMessage), 
             "# CharsM" = mean(numCharsPerMessage),
             numWordsPerMessageSE = sd(numWordsPerMessage)/sqrt(length(numWordsPerMessage)),
             "% NegativesM" = 100*mean(negativesRate),
             numNegativesSE = sd(negativesRate)/sqrt(length(negativesRate)),
             "% ComparativesM" = 100*mean(comparativesRate),
             "% SuperlativesM" = 100*mean(superlativesRate),
             "% High SpecificityM" = 100*mean(specificityRate, na.rm = T)) %>%
  gather(metric, mu, ends_with("M")) %>%
  #gather(garbage, se, ends_with("SE")) %>%
  mutate("metric (per message)" = gsub(".$", "", metric)) %>%
  select(-ends_with("SE"), -metric) %>%
  unite(comb, source,condition) %>%
  mutate(comb = ordered(comb, 
                        levels = c('human_far', 'human_split', 'human_close',
                                   'literal_far', 'literal_split', 'literal_close',
                                  'pragmatic_far', 'pragmatic_split', 'pragmatic_close'))) %>%
  spread(comb, mu)

topRow <- paste0(paste0('& \\multicolumn{3}{c}{', 
                        unique(combined$source), 
                        '}', collapse=''), '\\\\')
secondRow <- paste0('& ', 
                    paste0(rep(c("far", "split", "close"), 3), collapse='& '),
                    '\\\\')

addtorow <- list(
  pos = list(0), 
  command = c(paste0(topRow, secondRow, collapse = '\n'))
)

# Note: After copying into paper, I replace the alignment's | with @{\hspace{40pt}} 
# and also reorder the rows to not be alphabetical

cap <- ("Corpus statistics and statistics of samples from $\\Speaker_1$
  (rates per utterance). The human and artificial speakers show
  the same correlations between language use and context type.")
print(xtable(resultTable, label = "table:metrics", align = "llrrr|rrr|rrr",
              display=rep('f',11), digits = 1, caption = cap), 
      add.to.row= addtorow, include.rownames = FALSE, include.colnames = F,
      floating.environment = "table*", booktabs=T, hline.after = c(-1,0,nrow(resultTable)))

```

# Regressions

## Listener 

```{r}
conditionMod = glmer(numOutcome ~ condition*source + (1 | gameid), family = "binomial",
                     data = listener_df);
summary(conditionMod)
```

We find main effects of difficulty and of model; also interaction where humans are *much* better at "easy" condition while computers are only moderately better...

## Speaker

### Words

```{r}
summary(lmer(numRawWords ~ condition + (1|gameid), data = speakerStats %>% filter(source == 'human')))
```

### Characters

```{r}
summary(lmer(numRawChars ~ condition + (1|gameid), data = speakerStats %>% filter(source == 'human')))
```

```{r}
summary(lmer(numRawWords ~ condition + (1|gameid), data = speakerStats %>% filter(source == 'pragmatic')))
```

### Comparatives

```{r}
speakerStats$conditionHelmert <- speakerStats$condition
contrasts(speakerStats$conditionHelmert) <- matrix(c(2,-1, -1, 
                                                     0, 1, -1), 
                                                   ncol = 2)
contrasts(speakerStats$conditionHelmert)
summary(glmer(comparativesIndicator ~ conditionHelmert + (1|gameid), 
              family = 'binomial', data = speakerStats %>% filter(source == 'human')))
```

```{r}
summary(glmer(comparativesIndicator ~ conditionHelmert + (1|gameid), 
              family = 'binomial', data = speakerStats %>% filter(source == 'pragmatic')))
```

### Negatives

```{r}
summary(glmer(negativesIndicator ~ condition + (1|gameid), 
              family = 'binomial', data = speakerStats %>% filter(source == 'human')))
```

```{r}
summary(glmer(negativesIndicator ~ condition + (1|gameid), 
              family = 'binomial', data = speakerStats %>% filter(source == 'pragmatic')))
```

### High specificity

Statistically more or less of different things?

```{r}
summary(glmer(specificityIndicator ~ condition + (1 | gameid), 
             family = 'binomial', data = speakerStats %>% filter(source == 'human')))
```

```{r}
summary(glmer(specificityIndicator ~ condition + (1 | gameid), 
             family = 'binomial', data = speakerStats %>% filter(source == 'pragmatic')))
```

# Supplemental plots (for talks)

```{r}
combined %>% 
  group_by(gameid, condition) %>%
  summarize(numChars = mean(numRawChars)) %>%
  spread(condition, numChars) %>%
  ggplot(aes(x = close, y =far)) +
    geom_point() +
    geom_abline(linetype = 'dotted', slope = 1) + 
    ylim(0,30) +
    xlim(0, 30) +
    theme_few() +
  theme(aspect.ratio = 1)
```