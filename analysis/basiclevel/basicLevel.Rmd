---
title: "Basic-level emergence"
output: html_notebook
---

# Import libraries

```{r}
library(tidyverse)
library(ggthemes)
```

# Import data  

```{r}
raw_clicks = read_delim('../../data/categorical/artificial/clickedObj/clickedObjData.csv', '\t')
raw_drops = read_delim('../../data/categorical/artificial/drop/dropData.csv', '\t')
incompletes <- (raw_clicks %>% 
  group_by(gameid, condition) %>%
  tally() %>%
  filter(n < 60))$gameid
```

Filter out incompletes & compute cumulative accuracy. We also divide into quarters to compare games that ran different amounts of trials.

```{r}
d <- raw_clicks %>%
  filter(!(gameid %in% incompletes)) %>%
  mutate(acc = ifelse(correct == 'true', 1, 0)) %>%
  group_by(gameid) %>%
  mutate(condition = case_when(condition == 'over' ~ 'sub-majority',
                               condition == 'under' ~ 'super-majority',
                               condition == 'basic' ~ 'basic-majority',
                               condition == 'uniform' ~ 'uniform')) %>%
  mutate(quarter = floor((trialNum - 1) / (last(trialNum)/4))) %>%
  mutate(cumAcc = cumsum(acc)) %>%
  mutate(overallAcc = last(cumAcc)/last(trialNum)) %>%
  ungroup() %>%
  left_join(raw_drops, by = c('gameid', 'trialNum', 'intendedName')) %>%
  select(-ends_with('y'), -ends_with('x'), -starts_with('object'), -correct)
```

## Number games per condition

```{r}
d %>% 
  group_by(gameid, condition) %>%
  tally() %>%
  group_by(condition) %>%
  summarize(n = length(n))
```

# Results 

## Individual accuracy curves

```{r}
ggplot(d, aes(x = trialNum, y = cumAcc, group = gameid)) +
  geom_line() +
  theme_few() + 
  guides(color = FALSE) +
  ylab("cumulative accuracy")
```

## Accuracy by condition

```{r}
d %>% 
  group_by(condition, trialNum) %>%
  summarize(meanAcc = mean(cumAcc), se = sd(cumAcc)/sqrt(length(cumAcc))) %>%
  ggplot(aes(x = trialNum, y = meanAcc, color = condition)) +
    geom_line() +
#    geom_errorbar(aes(ymin = meanAcc - se, ymax = meanAcc + se)) +
    theme_few() +
    scale_color_colorblind()
```

## Accuracy by contextType

```{r}
d %>% 
  group_by(contextType, quarter) %>%
  summarize(meanAcc = mean(acc), se = sd(acc)/sqrt(length(acc))) %>%
  ggplot(aes(x = quarter, y = meanAcc)) +
    geom_line() +
    theme_few() + 
  facet_wrap(~ contextType)
```

One hypothesis is that in conditions where you don't see very many sub contexts, performance on those contexts should stay really bad or go down as you specialize for the other trials (especially in the 'under' condition). In the uniform condition, though, you should see it still going up because people need all the words. 

```{r}
d %>% 
  group_by(condition, contextType, quarter) %>%
  summarize(meanAcc = mean(acc), se = sd(acc)/sqrt(length(acc))) %>%
  ggplot(aes(x = quarter, y = meanAcc)) +
    geom_line() +
    theme_few() + 
    facet_grid(condition ~ contextType) +
    theme(aspect.ratio = 1)
```

# Post-test results

Import 

```{r}
postTest <- read_delim('../../data/categorical/artificial/postTestData/postTestData.csv', '\t') %>%
  mutate_each(funs(ifelse(. == "true", 1, 0)), 
              -iterationName, -gameid, -time, -label, -finalRole, -eventType) %>%
  gather(object, meaning, blueSquare1:stripedCircle2) %>%
  mutate(blue = grepl('blue', object),
         red = grepl('red', object),
         striped = grepl('striped', object),
         spotted = grepl('spotted', object),
         circle = grepl("Circle", object),
         square = grepl("Square", object))
```

## 'Validate' meanings against trajectory data

How do these post-test ratings compare to 'situtated' language use? Do players actually use the label during the game to mean the thing they explicitly say it means at the end?

```{r}
postTest %>% 
```

## Distribution of meanings 

How many objects does each label correspond to (i.e. how many meanings at sub-level vs. basic-level vs. super-level)

```{r}
postTest %>%
  group_by(gameid, finalRole, label) %>%
  summarize(numObjects = sum(meaning)) %>%
  left_join(d) %>%
  ggplot(aes(x = numObjects, y = ..density..)) +
    geom_histogram() +
    facet_wrap(~ condition) +
    theme_few()
```

## How often do players align on meanings?

On average, pairs only match on about 30% of the meanings they mark... 

```{r}
postTest %>%
  select(-time) %>%
  spread(finalRole, meaning) %>%
  filter(listener > 0 | speaker > 0) %>%
  group_by(gameid, label) %>%
  summarize(match = all(listener == speaker)) %>%
  group_by(gameid) %>%
  summarize(numMatching = sum(match) / length(match)) %>%
  left_join(d) %>%
  ggplot(aes(x = numMatching, y = ..density..)) +
    geom_histogram(binwidth = .2) +
    geom_vline(aes(xintercept = mean(numMatching))) +
    xlim(0,1) + 
    theme_few() +
    xlab('% matching')
  # facet_wrap(~ condition)
```

Unsurprisingly, pairs that aligned on meanings better performed better... 

```{r}
postTest %>%
  select(-time) %>%
  spread(finalRole, meaning) %>%
  filter(listener > 0 | speaker > 0) %>%
  group_by(gameid, label) %>%
  summarize(match = all(listener == speaker)) %>%
  group_by(gameid) %>%
  summarize(numMatching = sum(match) / 16) %>%
  left_join(d) %>%
  group_by(gameid) %>%
  summarize(numMatching = mean(numMatching), 
            overallAcc = mean(overallAcc)) %>%
  ggplot(aes(x = numMatching, y = overallAcc)) +
    geom_point() +
    theme_few() +
    geom_smooth(method = 'lm')
```

But note that pairs that didn't technically align that well could still perform pretty well if one partner simply has a stricter meaning than the other but the difference is never relevant. 

When people fail to perfectly align, do they do so in a predictable way? (e.g. one meaning a subset of the other?)

```{r}

```

## Vocab size by condition... 

```{r}
postTest %>%
  group_by(gameid, finalRole, label) %>%
  summarize(numObjects = sum(meaning)) %>%
  filter(numObjects > 0) %>%
  group_by(gameid, finalRole) %>%
  tally() %>%
  right_join(d) %>%
  group_by(condition) %>%
  summarize(vocabSize = mean(n, na.rm = T))
```

## Do basic-level & sub-level coexist?

```{r}
postTest %>% 
  group_by(gameid, finalRole, label) %>%
  filter(meaning == 1) %>%
  summarize(subordinate = sum(meaning) == 1,
            basic = (sum(meaning) == 2 & 
                       (all(red) | all(blue) | all(striped) | all(spotted)))) %>%
  group_by(gameid, finalRole) %>%
  summarize(numSub = sum(subordinate),
            numBasic = sum(basic)) %>%
  left_join(d) %>%
  ggplot(aes(x = numSub, y = numBasic, color = numSub > 0 & numBasic > 0)) +
    geom_point() +
  facet_wrap(~ condition)
  

postTest %>% 
  group_by(gameid, finalRole, label) %>%
  summarize(subordinate = sum(meaning) == 1,
            basic = 
```