{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### merging datasets from pilot0 (N=19) and pilot1 (N=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "from helpers import *\n",
    "from analysis_helpers import *\n",
    "import analysis_helpers as h\n",
    "reload(h)\n",
    "\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "exp_path = '3dObjects/sketchpad_basic'\n",
    "analysis_dir = os.getcwd()\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','data',exp_path))\n",
    "exp_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','experiments',exp_path))\n",
    "sketch_dir = os.path.abspath(os.path.join(os.getcwd(),'../../..','analysis',exp_path,'sketches','pilot1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D0 = pd.read_csv(os.path.join(os.path.join(analysis_dir,'sketchpad_basic_pilot0_group_data.csv')))\n",
    "D1 = pd.read_csv(os.path.join(os.path.join(analysis_dir,'sketchpad_basic_pilot1_group_data.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_D = pd.concat([D0,D1], join=\"inner\",ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get list of all valid gameids across session\n",
    "_valid_p0 = np.unique(_D[_D['iteration']=='pilot0']['gameID'].values)\n",
    "\n",
    "## 10/1/17: discussion with @rxdh: flag/exclude a game where the sketcher annotated drawing with words on at least two of the trials\n",
    "wordy = ['4196-e2f9bf3f-e1cf-4e54-8188-f5f3d07f171b']\n",
    "valid_p0 = [i for i in _valid_p0 if i not in wordy]\n",
    "tmp = pd.read_csv('valid_gameids_pilot1.csv')\n",
    "valid_p1 = np.unique(tmp['valid_gameids'].values)\n",
    "valid_gameids = list(valid_p0) + list(valid_p1)\n",
    "print '# valid games: ' + str(len(valid_gameids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter so that only valid gameid's are included in the final merged group data csv\n",
    "D = _D[_D['gameID'].isin(valid_gameids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add another cost-related dependent measure: mean pixel intensity (amount of ink spilled) -- to handle\n",
    "## some weird glitches in the num stroke count\n",
    "mean_intensity = []\n",
    "imsize = 100\n",
    "numpix = imsize**2\n",
    "thresh = 250\n",
    "for i,_d in D.iterrows():\n",
    "    imgData = _d['png']\n",
    "    filestr = base64.b64decode(imgData)\n",
    "    fname = os.path.join('sketch.png')\n",
    "    with open(fname, \"wb\") as fh:\n",
    "        fh.write(imgData.decode('base64'))\n",
    "    im = Image.open(fname).resize((imsize,imsize))\n",
    "    _im = np.array(im)\n",
    "    mean_intensity.append(len(np.where(_im[:,:,3].flatten()>thresh)[0])/numpix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add mean_intensity to the main D dataframe \n",
    "### btw: mean_intensity and numStrokes is about 0.43 spearman correlated.\n",
    "D = D.assign(mean_intensity=pd.Series(mean_intensity).values)\n",
    "print stats.spearmanr(D['mean_intensity'].values,D['numStrokes'].values)\n",
    "\n",
    "category = [h.objcat[t] for t in D.target.values]\n",
    "D = D.assign(category=pd.Series(category).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save out to merged group data csv\n",
    "D.to_csv('sketchpad_basic_merged_group_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out all sketches from both pilot0 and pilot1 in same way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## print out sketches with target & distractors from this game in separate folders\n",
    "import traceback\n",
    "backup_path_images = '/Users/judithfan/Dropbox/stimuli_repository/subordinate_allrotations_6_minified'\n",
    "\n",
    "_valid_gameids = valid_gameids[:3]\n",
    "\n",
    "## get list of all incorrect sketch path names\n",
    "incorrect_trial_paths = []\n",
    "\n",
    "target_sketch_dir = os.path.join(analysis_dir,'sketches','sketch')\n",
    "target_3D_dir = os.path.join(analysis_dir,'sketches','target')\n",
    "distractor1_3D_dir = os.path.join(analysis_dir,'sketches','distractor1')\n",
    "distractor2_3D_dir = os.path.join(analysis_dir,'sketches','distractor2')\n",
    "distractor3_3D_dir = os.path.join(analysis_dir,'sketches','distractor3')\n",
    "out_paths = [target_3D_dir,distractor1_3D_dir,distractor2_3D_dir,distractor3_3D_dir]\n",
    "\n",
    "\n",
    "if not os.path.exists(target_3D_dir):\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches','target'))\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches','distractor1'))\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches','distractor2'))\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches','distractor3'))\n",
    "    os.makedirs(os.path.join(analysis_dir,'sketches','sketch'))    \n",
    "\n",
    "run_this = 0\n",
    "if run_this:\n",
    "    for g in valid_gameids:\n",
    "        print 'Printing out sketches from game: ' + g\n",
    "        _D = D[(D.gameID==g)]\n",
    "        _D = _D.sort_values(by=['target'])\n",
    "        _i = 1\n",
    "        textsize=12\n",
    "        fig = plt.figure(figsize=(16,6))        \n",
    "        for i,_d in _D.iterrows():\n",
    "            imgData = _d['png']\n",
    "            filestr = base64.b64decode(imgData)\n",
    "            if not os.path.exists(target_sketch_dir):\n",
    "                os.makedirs(target_sketch_dir)\n",
    "            fname = os.path.join(target_sketch_dir,'gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '.png')\n",
    "            with open(fname, \"wb\") as fh:\n",
    "                fh.write(imgData.decode('base64'))\n",
    "            im = Image.open(fname)\n",
    "            im.save(fname)\n",
    "            \n",
    "            if _d['outcome']==0:\n",
    "                incorrect_trial_paths.append('gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '.png')            \n",
    "\n",
    "            targetname = _d['target']\n",
    "            distractors = [_d['Distractor1'],_d['Distractor2'],_d['Distractor3']]\n",
    "            full_list = [_d['target'],_d['Distractor1'],_d['Distractor2'],_d['Distractor3']]         \n",
    "            \n",
    "            for (i,d) in enumerate(full_list):\n",
    "                if os.path.exists(backup_path_images):\n",
    "                    if not np.isnan(_d['pose']):\n",
    "                        pose = _d['pose']\n",
    "                        fn = os.path.join(backup_path_images,get_actual_pose(d,pose)[0])\n",
    "                    else:\n",
    "                        fn = os.path.join(backup_path_images,get_actual_pose(d,35)[0])\n",
    "                else:\n",
    "                    if hasattr(_d, 'pose'):\n",
    "                        pose = _d['pose']\n",
    "                        URL = build_url_from_filenames(get_actual_pose(d,pose)[0])\n",
    "                    else:\n",
    "                        URL = full_dict[d]\n",
    "                    fn = cStringIO.StringIO(urllib.urlopen(URL).read())\n",
    "                fig = plt.figure(figsize=(8,8))                    \n",
    "                im = Image.open(fn)\n",
    "                im = im.resize((256,256), Image.ANTIALIAS).convert('RGB')                                \n",
    "                out_dirs = [target_3D_dir,distractor1_3D_dir,distractor2_3D_dir,distractor3_3D_dir]                \n",
    "                out_path = os.path.join(out_dirs[i],'gameID_' + _d['gameID'] + '_trial_' + str(_d['trialNum']) + '.png')\n",
    "                im.save(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save out number of incorrect trial paths\n",
    "print \"Number of incorrect trial paths: {}\".format(str(len(incorrect_trial_paths)))\n",
    "with open('incorrect_trial_paths.txt', 'w') as f:\n",
    "    for path in incorrect_trial_paths:\n",
    "        f.write(path + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### only consider correct trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "further_strokes, closer_strokes, further_svgLength, closer_svgLength,\\\n",
    "further_svgStd, closer_svgStd, further_svgLengthPS, closer_svgLengthPS, \\\n",
    "further_drawDuration, closer_drawDuration, further_accuracy, closer_accuracy, \\\n",
    "further_pixelintensity, closer_pixelintensity = h.get_summary_stats(D,valid_gameids, correct_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## checking for accuracy in close condition broken down by category\n",
    "bird_accuracy, car_accuracy, chair_accuracy, dog_accuracy = h.get_close_accuracy_by_category(D,valid_gameids)\n",
    "acc = pd.DataFrame([bird_accuracy,car_accuracy,chair_accuracy,dog_accuracy])\n",
    "acc = acc.transpose()\n",
    "acc.columns = ['bird','car','chair','dog']\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.barplot(data=acc)\n",
    "plt.ylabel('viewer accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# destination for plots\n",
    "plot_save_dir = './plots'\n",
    "\n",
    "# aesthetic settings\n",
    "marker_color = (0.4,0.7,0.4)\n",
    "marker_size = 100\n",
    "alpha_val = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "lb = 0\n",
    "ub = 25\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_strokes,further_strokes,marker_size,marker_color,edgecolors='none',alpha=alpha_val)\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.title('number of strokes')\n",
    "plt.xlabel('close')\n",
    "plt.ylabel('far')\n",
    "plt.savefig(os.path.join(plot_save_dir,'scatter_num_strokes.pdf'))\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "lb = 0\n",
    "ub = 0.12\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_pixelintensity,further_pixelintensity,marker_size,marker_color,edgecolors='none',alpha=alpha_val)\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.title('mean pixel intensity')\n",
    "plt.xlabel('close')\n",
    "plt.ylabel('far')\n",
    "plt.savefig(os.path.join(plot_save_dir,'scatter_pixel_intensity.pdf'))\n",
    "plt.close()\n",
    "\n",
    "## note: only correct trials are included to compute these stats, EXCEPT for the accuracy plot. \n",
    "fig = plt.figure(figsize=(8,4))\n",
    "lb = 0\n",
    "ub = 1.03\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_accuracy,further_accuracy,marker_size,marker_color,edgecolors='none',alpha=alpha_val)\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.title('accuracy')\n",
    "plt.xlabel('closer')\n",
    "plt.ylabel('further')\n",
    "plt.subplot(1,2,2)\n",
    "lb = 0\n",
    "ub = 60\n",
    "plt.plot([lb,ub],[lb,ub],'k--')\n",
    "plt.scatter(closer_drawDuration,further_drawDuration,marker_size,marker_color,edgecolors='none',alpha=alpha_val)\n",
    "plt.xlim([lb,ub])\n",
    "plt.ylim([lb,ub])\n",
    "plt.title('draw duration (sec)')\n",
    "plt.xlabel('closer')\n",
    "plt.ylabel('further')\n",
    "plt.tight_layout()\n",
    "save_out = 1\n",
    "plt.savefig('plots/scatter_performance.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numStrokes = pd.DataFrame(np.vstack((closer_strokes,further_strokes)).transpose(), \\\n",
    "                 columns = ['close','far'])\n",
    "diffStrokes = pd.DataFrame((further_strokes-closer_strokes).transpose(), \\\n",
    "                 columns = ['far - close'])\n",
    "pixIntensity = pd.DataFrame(np.vstack((closer_pixelintensity,further_pixelintensity)).transpose(), \\\n",
    "                 columns = ['close','far'])\n",
    "diffPix = pd.DataFrame((further_pixelintensity-closer_pixelintensity).transpose(), \\\n",
    "                 columns = ['far - close'])\n",
    "accuracy = pd.DataFrame(np.vstack((closer_accuracy,further_accuracy)).transpose(), \\\n",
    "                 columns = ['close','far'])\n",
    "drawDuration = pd.DataFrame(np.vstack((closer_drawDuration,further_drawDuration)).transpose(), \\\n",
    "                 columns = ['close','far'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bar aesthetics\n",
    "my_palette = sns.diverging_palette(200, 20, n=8)\n",
    "my_palette = sns.cubehelix_palette(8)\n",
    "my_palette = sns.color_palette(\"RdBu\", n_colors=5)\n",
    "my_palette = sns.cubehelix_palette(5, start=.5, rot=-.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.barplot(data=pixIntensity,ci=95,palette=my_palette)\n",
    "plt.title('mean pixel intensity')\n",
    "h = plt.yticks(np.arange(0,0.08,0.01))\n",
    "plt.savefig('plots/bar_pixel_intensity.pdf')\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.barplot(data=numStrokes,ci=95,palette=my_palette)\n",
    "plt.title('number of strokes')\n",
    "plt.savefig('plots/bar_num_strokes.pdf')\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(3,7))\n",
    "sns.barplot(data=diffStrokes,ci=95,palette=my_palette)\n",
    "plt.ylabel(r'$\\Delta$ num strokes (far - close)')\n",
    "plt.ylim([-4,2])\n",
    "plt.savefig('plots/bar_diff_strokes.pdf')\n",
    "plt.tight_layout()\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(3,7))\n",
    "sns.barplot(data=diffPix,ci=95,palette=my_palette)\n",
    "plt.ylabel(r'$\\Delta$ pixel intensity (far - close)')\n",
    "plt.ylim([-0.018,0.005])\n",
    "plt.savefig('plots/bar_diff_intensity.pdf')\n",
    "plt.tight_layout()\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.barplot(data=accuracy,ci=95,palette=my_palette)\n",
    "plt.title('accuracy')\n",
    "plt.ylim([0,1.03])\n",
    "plt.savefig('plots/bar_accuracy.pdf')\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.barplot(data=drawDuration,ci=95,palette=my_palette)\n",
    "plt.title('draw duration')\n",
    "plt.savefig('plots/bar_draw_duration.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## length of stroke across stroke number\n",
    "__D = D[D['numStrokes']<500]\n",
    "_D = __D[__D['condition']=='closer']\n",
    "num_trials = np.shape(_D)[0]\n",
    "max_length = 50\n",
    "CNum_curves = np.empty((num_trials,max_length,))\n",
    "CNum_curves[:] = np.NAN\n",
    "for i in np.arange(num_trials):\n",
    "    svgs = ast.literal_eval(_D.iloc[i]['svg'])\n",
    "    ns = len(svgs)\n",
    "    num_curves = [len([m.start() for m in re.finditer('c', s)]) for s in svgs]\n",
    "    if num_curves > max_length:\n",
    "        num_curves = num_curves[:max_length]\n",
    "    CNum_curves[i,:len(num_curves)] = num_curves\n",
    "\n",
    "_D = __D[__D['condition']=='further']\n",
    "num_trials = np.shape(_D)[0]\n",
    "max_length = 50\n",
    "FNum_curves = np.empty((num_trials,max_length,))\n",
    "FNum_curves[:] = np.NAN\n",
    "for i in np.arange(num_trials):\n",
    "    svgs = ast.literal_eval(_D.iloc[i]['svg'])\n",
    "    ns = len(svgs)\n",
    "    num_curves = [len([m.start() for m in re.finditer('c', s)]) for s in svgs]\n",
    "    if num_curves > max_length:\n",
    "        num_curves = num_curves[:max_length]\n",
    "    FNum_curves[i,:len(num_curves)] = num_curves    \n",
    "\n",
    "# plot and save out    \n",
    "sns.set_style('white')\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "marker_color = (0.4,0.8,0.4)\n",
    "marker_color2 = (0.2,0.5,0.2)\n",
    "plt.plot(np.nanmean(CNum_curves,axis=0),color=(marker_color), label='close')\n",
    "plt.plot(np.nanmean(FNum_curves,axis=0),color=(marker_color2), label='far')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('number of spline segments')\n",
    "plt.xlabel('stroke number')\n",
    "plt.savefig('plots/line_spline_segs_by_stroke.pdf')\n",
    "plt.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = pd.read_csv('sketchpad_basic_merged_group_data.csv')\n",
    "\n",
    "# filter so only looking at pilot1 because we have pose information on those games\n",
    "D = D[D.iteration=='pilot1']\n",
    "\n",
    "# filter out incorrect and invalid trials as well\n",
    "incorrects = pd.read_csv('./incorrect_trial_paths.txt',header=None)[0].values\n",
    "invalids = pd.read_csv('./invalid_trial_paths.txt',header=None)[0].values\n",
    "fname = []\n",
    "for i,j in zip(D['gameID'].values,D['trialNum']):\n",
    "    fname.append('gameID_' + i + '_trial_' + str(j) + '.png')\n",
    "D = D.assign(fname=pd.Series(fname).values)  \n",
    "D = D[~D['fname'].isin(incorrects)]\n",
    "D = D[~D['fname'].isin(invalids)]\n",
    "print str(np.shape(D)[0]) + ' records in merged dataframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_dists = './RSA/refModule/json/strict-similarity-pragmatics-conv4_2.json'\n",
    "dists = pd.read_json('./RSA/refModule/json/strict-similarity-pragmatics-conv4_2.json')\n",
    "dists = dists.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sketch_label = [(i[-12:] + '_' + str(j)) for i,j in zip(D['gameID'].values,D['trialNum'].values)]\n",
    "D = D.assign(sketch_label=pd.Series(sketch_label).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dist_labels = dists.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dT = []\n",
    "dD1 = []\n",
    "dD2 = []\n",
    "dD3 = []\n",
    "for i, _d in D.iterrows():\n",
    "    sketch = _d['sketch_label']\n",
    "    pose = int(_d['pose'])\n",
    "    target = _d['target'] + '_' + '{:04d}'.format(pose)\n",
    "    distractor1 = _d['Distractor1'] + '_' + '{:04d}'.format(pose)\n",
    "    distractor2 = _d['Distractor2'] + '_' + '{:04d}'.format(pose)\n",
    "    distractor3 = _d['Distractor3'] + '_' + '{:04d}'.format(pose)\n",
    "    dT.append(dists[sketch][target])\n",
    "    dD1.append(dists[sketch][distractor1])\n",
    "    dD2.append(dists[sketch][distractor2])\n",
    "    dD3.append(dists[sketch][distractor3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = D.assign(dT=pd.Series(dT).values)\n",
    "D = D.assign(dD1=pd.Series(dD1).values)\n",
    "D = D.assign(dD2=pd.Series(dD2).values)\n",
    "D = D.assign(dD3=pd.Series(dD3).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "_D = D[D.condition=='closer']\n",
    "distractor_dists = np.hstack((_D.dD1.values,_D.dD2.values,_D.dD3.values))\n",
    "sns.kdeplot(distractor_dists, shade=True, color=(0.3,0.3,0.3),label='distractors')\n",
    "sns.kdeplot(_D.dT.values, shade=True, color=(0.9,0.7,0.1),label='target')\n",
    "plt.ylim([0,1.6])\n",
    "plt.xlim([-1,1])\n",
    "plt.xlabel('distance')\n",
    "plt.title('close')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "_D = D[D.condition=='further']\n",
    "distractor_dists = np.hstack((_D.dD1.values,_D.dD2.values,_D.dD3.values))\n",
    "sns.kdeplot(distractor_dists, shade=True, color=(0.3,0.3,0.3),label='distractors')\n",
    "sns.kdeplot(_D.dT.values, shade=True, color=(0.9,0.7,0.1),label='target')\n",
    "plt.ylim([0,1.6])\n",
    "plt.xlim([-1,1])\n",
    "plt.xlabel('distance')\n",
    "plt.title('far')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sumlogprob(a,b):\n",
    "    if (a > b):\n",
    "        return a + np.log1p(np.exp(b-a))\n",
    "    else:\n",
    "        return b + np.log1p(np.exp(a-b))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = pd.read_csv('./RSA/bdaOutput/testingParams_alldata.csv')\n",
    "# filter out rows where posterior probability is -Infinity\n",
    "# P = P[P.posteriorProb!='-Infinity']\n",
    "print np.shape(P)\n",
    "\n",
    "X = P.groupby(['similarityMetric', 'speakerModel'])['logLikelihood']\n",
    "Y = X.apply(lambda x: reduce(sumlogprob,x) - np.log(len(x)))\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette(\"Paired\")\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "seq = [('early','S0'),('early','S1'),('strict-mid','S0'),('strict-mid','S1'),('nonstrict-high','S0'),('nonstrict-high','S1')]\n",
    "sns.barplot(data=Y.transpose(),palette=colors, order = seq)\n",
    "plt.ylim([-20300,-19000])\n",
    "plt.ylabel('log likelihood')\n",
    "plt.title('model comparison: all data',fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  far only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = pd.read_csv('./RSA/bdaOutput/testingParams_faronly.csv')\n",
    "# filter out rows where posterior probability is -Infinity\n",
    "# P = P[P.posteriorProb!='-Infinity']\n",
    "print np.shape(P)\n",
    "\n",
    "X = P.groupby(['similarityMetric', 'speakerModel'])['logLikelihood']\n",
    "Y = X.apply(lambda x: reduce(sumlogprob,x) - np.log(len(x)))\n",
    "Y = pd.DataFrame(Y)\n",
    "print Y\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette(\"Paired\")\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "seq = [('early','S0'),('early','S1'),('strict-mid','S0'),('strict-mid','S1'),('nonstrict-high','S0'),('nonstrict-high','S1')]\n",
    "sns.barplot(data=Y.transpose(),palette=colors, order = seq)\n",
    "plt.ylim([-10200,-9200])\n",
    "plt.ylabel('log likelihood')\n",
    "plt.title('model comparison: far only',fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P.sort_values([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
