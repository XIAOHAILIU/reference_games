{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import lots of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pylab as pyl\n",
    "import nltk as nltk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "%matplotlib inline\n",
    "#enable longer display\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import annotated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d_raw = pd.read_csv('../../data/tangrams/old/oldTangrams.csv')\n",
    "\n",
    "# Drop time column\n",
    "d = (d_raw\n",
    "    .copy()\n",
    "    .drop('time', 1)\n",
    "    .query('tangram != \"0\"')\n",
    "    .query('tangram != \"*\"'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d['tokens'] = [[word for word in nltk.word_tokenize(sentence.lower()) if word.isalpha()]\n",
    "               for sentence in d['contents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get number of words used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d['numWords'] = [pd.value_counts(words).sum() for words in d['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 1: Generate file for POS analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d['pos'] = [[pos for (key, pos) in nltk.pos_tag(rowTokens, tagset = 'universal')] \n",
    "            for rowTokens in d['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all unique POS labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posSet = set({})\n",
    "for row in d['pos'] :\n",
    "    for pos in row :\n",
    "        posSet.add(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get counts for each POS label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pos in posSet :\n",
    "    colName = pos + \"num\"\n",
    "    d[colName] = [posList.count(pos) for posList in d['pos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to csv for plotting in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(d.drop([\"pos\", \"contents\", \"tokens\"], 1)\n",
    " .to_csv(\"posTagged.csv\", index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 2: Calculate indicator words for tangrams/rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, get list of words in first round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter down to first round\n",
    "d_round1 = d[d['roundNum'] == 1]\n",
    "\n",
    "# Pull out all tokens and collapse into count dict\n",
    "tokenDict = Counter([item for sublist in d_round1['tokens'].tolist()\n",
    "                     for item in sublist])\n",
    "\n",
    "# Pull out all words that occur more than once\n",
    "wordList = [word for (word,count) in tokenDict.items() if count > 1]\n",
    "print(wordList[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all game ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gameidList = pd.unique(d.gameid.ravel()).tolist()\n",
    "print(gameidList[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all tangram names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tangramList = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
    "print(tangramList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to select words & counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getWordCounts(df, gameid, roundNum, tangram = None) :\n",
    "    roundCond = 'roundNum == ' + roundNum\n",
    "    gameidCond = 'gameid == \"' + gameid + '\"'\n",
    "    if(tangram is not None) :\n",
    "        tangramCond = 'tangram == \"' + tangram + '\"'\n",
    "        cond = \" and \".join((roundCond, gameidCond, tangramCond))\n",
    "    else :\n",
    "        cond = \" and \".join((roundCond, gameidCond))\n",
    "    relevantRow = df.query(cond)\n",
    "    return Counter([item for sublist in relevantRow['tokens'].tolist() \n",
    "                    for item in sublist])\n",
    "\n",
    "#creates mini dataframe that grabs the words used in round n for a given tangram and gameid\n",
    "def selectTangramRoundWords(df, tangram, roundNum, gameid):\n",
    "    wordCounts = getWordCounts(df, gameid, roundNum, tangram)\n",
    "    return wordCounts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to compute PMIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that merging is really costly -- if we need to speed it up, this might be the first target. Can also vectorize the log operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns a table with the all words above 0 PMI and their counts for a given tangram\n",
    "#calculate the probability for words given tangram A ------ p(x|y)\n",
    "def makeMyPMI(df, tangram, roundNum, gameid, totals):\n",
    "\n",
    "    # count words w/in tangram\n",
    "    tangramCounts = getWordCounts(df, gameid, roundNum, tangram)\n",
    "\n",
    "    #total number of words \n",
    "    tangramNumWords = (1 if sum(tangramCounts.values()) == 0 \n",
    "                       else sum(tangramCounts.values()))\n",
    "\n",
    "    #dataframe to compare \n",
    "    indicatorDF = pd.merge(pd.DataFrame(tangramCounts.items(), columns=['word', 'count']),\n",
    "                           pd.DataFrame(totals[\"counts\"].items(), columns=['word', 'totalCount']),\n",
    "                           on='word', how = 'inner')\n",
    "\n",
    "    #calculate PMI without log first. Having trouble with float issues. \n",
    "    indicatorDF['roughPMI'] = ((indicatorDF['count']/tangramNumWords)\n",
    "                                / (indicatorDF['totalCount']/totals[\"numWords\"]))\n",
    "    indicatorDF['logPMI'] = [math.log10(num) for num in indicatorDF['roughPMI']]\n",
    "    \n",
    "    #remove column rough PMI\n",
    "    indicatorDF = indicatorDF.drop('roughPMI', 1)\n",
    "    \n",
    "    return indicatorDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out PMIs & matching rates for all words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we do a sloppy optimization by only computing total counts once and only when necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def memoize(d, gameid, counts) : \n",
    "    if \"counts\" not in counts : \n",
    "        counts[\"counts\"] = getWordCounts(d, gameid, \"1\")\n",
    "        counts[\"numWords\"] = float(sum(counts[\"counts\"].values()))\n",
    "        return counts\n",
    "    else \n",
    "        return counts\n",
    "\n",
    "with open('matchAndPMI.csv', 'ab') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['word', 'match', 'pmi', 'total'])\n",
    "    for word in wordList :\n",
    "        print(word)\n",
    "        pmi = 0\n",
    "        match = 0\n",
    "        total = 0\n",
    "        for gameid in gameidList:  \n",
    "            memoizedCounts = {}\n",
    "            for tangram in tangramList:\n",
    "                memoizedCounts = memoize(d, gameid, memoizedCounts)\n",
    "                round1WordList = selectTangramRoundWords(d, tangram, \"1\", gameid)\n",
    "                total = total + 1 if word in round1WordList else total\n",
    "                if word in round1WordList :\n",
    "                    PMI_df = makeMyPMI(d, tangram, \"1\", gameid, memoizedCounts)\n",
    "                    pmi = pmi + PMI_df[PMI_df['word'] == word]['logPMI'].tolist()[0]\n",
    "                    round6WordList = selectTangramRoundWords(d, tangram, \"6\", gameid)\n",
    "                    match = (match + 1 if (word in round1WordList and word in round6WordList)\n",
    "                             else match)\n",
    "        writer.writerow([word, float(match) / float(total), pmi/total, total])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bootstrap analysis (might want to move to R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grab words with highestPMI for a given tangram/gameid\n",
    "def highestPMIWords(d, tangram, roundNum, gameid):\n",
    "    allTangramCounts = {}\n",
    "    allTangramCounts['counts'] = getWordCounts(d, gameid, \"1\")\n",
    "    allTangramCounts['numWords'] = float(sum(allTangramCounts[\"counts\"].values()))\n",
    "\n",
    "    PMIdf = makeMyPMI(d, tangram, roundNum, gameid, allTangramCounts)\n",
    "    #if PMIdf has words, pull out max values, it is empty return it as is\n",
    "    if len(PMIdf.index) > 0:\n",
    "        PMI_values = PMIdf.logPMI.unique()\n",
    "        maxPMI = PMI_values.max()\n",
    "        PMIdf = PMIdf.loc[PMIdf['logPMI'] == maxPMI]\n",
    "        PMIdfword = PMIdf['word']\n",
    "        return PMIdfword.tolist()\n",
    "    else: \n",
    "        return PMIdf\n",
    "\n",
    "numSamples = 100\n",
    "with open('PMIbootstrap.csv', 'wb') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['tangram', 'gameid', 'numCandidates', 'match', 'highest'])\n",
    "    for gameid in gameidList :\n",
    "        for tangram in tangramList :\n",
    "            round1Words = selectTangramRoundWords(d, tangram, \"1\", gameid)\n",
    "            if len(round1Words) > 0:\n",
    "                # First, write highest PMI match\n",
    "                highPMIWords = highestPMIWords(d, tangram, \"1\", gameid)\n",
    "                round6Words = selectTangramRoundWords(d, tangram, \"6\", gameid)\n",
    "                match = np.mean([1 if word in round6Words else 0 for word in highPMIWords ])\n",
    "                writer.writerow([tangram, gameid, len(highPMIWords), match, \"highest\"])\n",
    "\n",
    "                # Next, take a bunch of null samples\n",
    "                for i in range(numSamples) :\n",
    "                    randomWord = np.random.choice(round1Words)\n",
    "                    match = np.mean([1 if randomWord in round6Words else 0])\n",
    "                    writer.writerow([tangram, gameid, 1, match, \"null\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfForDict = test2.copy()\n",
    "dfForDict = dfForDict[20:500]\n",
    "\n",
    "#http://stackoverflow.com/questions/16333296/how-do-you-create-nested-dict-in-python\n",
    "#set up the nested dictionaries\n",
    "tangramDict = {}\n",
    "tangramDict['tangram'] = {}\n",
    "tangramDict['tangram']['roundNum'] = {}\n",
    "tangramDict['tangram']['roundNum']['word'] = 'count'\n",
    "tangramDict\n",
    "\n",
    "#populate the dictionary \n",
    "\n",
    "#http://stackoverflow.com/questions/635483/what-is-the-best-way-to-implement-nested-dictionaries-in-python\n",
    "\n",
    "\n",
    "dfForDict = dfForDict[['roundNum', 'tangram', 'tokens']]\n",
    "dfForDict = dfForDict.sort(['roundNum', 'tangram'], ascending = [True, True])\n",
    "#rearrange columns\n",
    "cols = dfForDict.columns.tolist()\n",
    "cols = ['tangram', 'roundNum', 'tokens']\n",
    "dfForDict = dfForDict[cols]\n",
    "#dfForDict = dfForDict.groupby('roundNum')\n",
    "# dfForDict = dfForDict[2:500]\n",
    "\n",
    "\n",
    "import pprint\n",
    "\n",
    "class Vividict(dict):\n",
    "    def __missing__(self, key):\n",
    "        value = self[key] = type(self)()\n",
    "        return value\n",
    "    \n",
    "d = Vividict()\n",
    "\n",
    "# d['foo']['bar']\n",
    "# d['foo']['baz']\n",
    "# d['fizz']['buzz']\n",
    "# d['primary']['secondary']['tertiary']['quaternary']\n",
    "\n",
    "\n",
    "\n",
    "pprint.pprint(d)\n",
    "\n",
    "#http://stackoverflow.com/questions/18695605/python-pandas-dataframe-to-dictionary\n",
    "\n",
    "#{g: f['contents'].tolist() for f,g in dfForDict.groupby(\"tangram\") for k,g in dfForDict.groupby(\"roundNum\")}\n",
    "\n",
    "#{k: g[\"value\"].tolist() for k,g in ptest.groupby(\"id\")}\n",
    "\n",
    "\n",
    "def retro_dictify(frame):\n",
    "    d = {}\n",
    "    for row in frame.values:\n",
    "        here = d\n",
    "        for elem in row[:-2]:\n",
    "            if elem not in here:\n",
    "                here[elem] = {}\n",
    "            here = here[elem]\n",
    "        here[row[-2]] = row[-1]\n",
    "    return d\n",
    "\n",
    "retro_dictify(dfForDict)\n",
    "\n",
    "\n",
    "\n",
    "# d = defaultdict(int)\n",
    "# for word in bigWordList :\n",
    "#   for tangram in tangrams :\n",
    "#     for roundNum in roundNums :\n",
    "#       d[tangram + ‘,’ + str(roundNum) + ‘,’ + word] += \n",
    "#countOccurences(word, tangram, roundNum)\n",
    "\n",
    "# writer = csv.writer(open(’tangramWordCounts.csv', 'wb'))\n",
    "# for key, value in d.items():\n",
    "#   writer.writerow([key, value])\n",
    "\n",
    "#dfForDict.groupby()\n",
    "\n",
    "#[f(x) for x in list]\n",
    "\n",
    "dfForDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#use highPMI list to filter words for tangrams over the next rounds\n",
    "#need list of words and their frequency for each round\n",
    "#need 6 dictionaries/frequencies merged by the highPMI words\n",
    "\n",
    "#the dataframe with all tangrams and all rounds\n",
    "bigFrame = test2.copy()\n",
    "#bigFrameTangram = bigFrame[bigFrame.tangram == 'A']\n",
    "\n",
    "#cumWordsAndCounts = highPMI\n",
    "\n",
    "def createFrequencyTable(roundNum, tangram):\n",
    "    #filter for the tangram desired\n",
    "    bigFrameTangram = bigFrame[bigFrame.tangram == tangram]\n",
    "    bigFrameTangram = bigFrame[bigFrame.roundNum == roundNum]\n",
    "    cumWordsAndCounts = makeMyPMI(tangram)\n",
    "    #print cumWordsAndCounts\n",
    "    #go from 2-6 because round1 is included with cumWordsAndCounts \n",
    "    #for roundNum in [2,3,4,5,6]:\n",
    "    #filter by roundNum\n",
    "    bigFrameTangram = bigFrameTangram[bigFrameTangram.roundNum == roundNum]\n",
    "\n",
    "    #bigDictionary turns all of the tokens used to talk about tangram A over round into a dictionary\n",
    "    smallDictionary = bigFrameTangram['tokens'].tolist()\n",
    "    smallDictionary = [item for sublist in smallDictionary for item in sublist]\n",
    "    #get dictionary counter for words used for tangram A\n",
    "    smallDictionary = Counter(smallDictionary)\n",
    "\n",
    "    #convert to normal dictionary in order to pull out counts more easily\n",
    "    #smallDictionary = smallDictionary.items() \n",
    "\n",
    "    #turn dictionary with counts into dataframe\n",
    "    #dataframe to look at words and their counts for tangram A in round 1\n",
    "    smallWordsAndCounts = pd.DataFrame(smallDictionary.items(), columns=['word', 'count'])\n",
    "    #smallWordsAndCount['tangram'] = tan\n",
    "    #dataframe which will contain words and the frequencies of them on rounds 1 through 6\n",
    "    #print cumWordsAndCounts[:5][:5]\n",
    "    #cumWordsAndCounts = pd.concat([cumWordsAndCounts, smallWordsAndCounts])\n",
    "    #print cumWordsAndCounts[:5][:5]\n",
    "\n",
    "    #reset bigFrame so we can go to the next roundNum\n",
    "    #bigFrameTangram = bigFrame[bigFrame.tangram == tangram]\n",
    "\n",
    "    return smallWordsAndCounts\n",
    "    \n",
    "\n",
    "wordFrequency_A = createFrequencyTable(2, 'A')\n",
    "\n",
    "wordFrequency_A\n",
    "\n",
    "# d = defaultdict(int)\n",
    "# for word in bigWordList :\n",
    "#   for tangram in tangrams :\n",
    "#     for roundNum in roundNums :\n",
    "#       d[tangram + ‘,’ + str(roundNum) + ‘,’ + word] += countOccurences(word, tangram, roundNum)\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "# allTangramsFreqs = pd.DataFrame()\n",
    "# for tangram in ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']:\n",
    "#     #creates the words and frequencies over rounds df for one tangram\n",
    "#     oneTangramFreq = createFrequencyTable(tangram)\n",
    "#     #joins all words and their frequencies over rounds for each tangram\n",
    "#     allTangramsFreqs = pd.concat([allTangramsFreqs, oneTangramFreq], axis=1)\n",
    "\n",
    "# #change the column names to tangram letter and correct round numbers\n",
    "# allTangramsFreqs.columns = ['A', '1', '2', '3', '4', '5', '6', 'B', '1', '2', '3', '4', '5', '6', \n",
    "#                            'C', '1', '2', '3', '4', '5', '6', 'D', '1', '2', '3', '4', '5', '6', \n",
    "#                            'E', '1', '2', '3', '4', '5', '6', 'F', '1', '2', '3', '4', '5', '6', \n",
    "#                            'G', '1', '2', '3', '4', '5', '6', 'H', '1', '2', '3', '4', '5', '6', \n",
    "#                            'I', '1', '2', '3', '4', '5', '6', 'J', '1', '2', '3', '4', '5', '6',\n",
    "#                            'K', '1', '2', '3', '4', '5', '6', 'L', '1', '2', '3', '4', '5', '6']\n",
    "# allTangramsFreqs.to_csv(\"allTangramsFreqs.csv\")   \n",
    "\n",
    "    \n",
    "\n",
    "len(pd.unique(test1.gameid.ravel()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use highPMI list to filter words for tangrams over the next rounds\n",
    "#need list of words and their frequency for each round\n",
    "#need 6 dictionaries/frequencies merged by the highPMI words\n",
    "\n",
    "#the dataframe with all tangrams and all rounds\n",
    "bigFrame = test2.copy()\n",
    "\n",
    "def createFrequencyTable(tangram, roundNum):\n",
    "    #filter for the tangram desired\n",
    "    myDictDf = bigFrame[bigFrame.tangram == tangram]\n",
    "    myDictDf = myDictDf[myDictDf.roundNum == roundNum]\n",
    "\n",
    "    #bigDictionary turns all of the tokens used to talk about tangram A over round into a dictionary\n",
    "    smallDictionary = myDictDf['tokens'].tolist()\n",
    "    smallDictionary = [item for sublist in smallDictionary for item in sublist]\n",
    "    #get dictionary counter for words used for tangram A\n",
    "    smallDictionary = Counter(smallDictionary)\n",
    "\n",
    "    #turn dictionary with counts into dataframe\n",
    "    #dataframe to look at words and their counts for tangram A in round 1\n",
    "    smallWordsAndCounts = pd.DataFrame(smallDictionary.items(), columns=['word', 'count'])\n",
    "\n",
    "    return smallWordsAndCounts\n",
    "    \n",
    "\n",
    "createFrequencyTable('A', 3)\n",
    "\n",
    "d = defaultdict(int)\n",
    "for word in bigWordList :\n",
    "  for tangram in tangrams :\n",
    "    for roundNum in roundNums :\n",
    "      d[tangram + ‘,’ + str(roundNum) + ‘,’ + word] += countOccurences(word, tangram, roundNum)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Type and token probabilities over rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tanDiffs = test2.copy()\n",
    "tanDiffs = tanDiffs.groupby(['tangram']).sum()\n",
    "\n",
    "tans = tanDiffs.loc['A': 'K', 'numWords': 'numWords']\n",
    "tans2 = tans['numWords'].tolist()\n",
    "\n",
    "y = tans2\n",
    "x = ['A','B','C','D','E','F','G','H','I','J','K']\n",
    "width = 1/1.5\n",
    "#plt.bar(x, y, width, color=\"blue\")\n",
    "\n",
    "#fig = plt.gcf()\n",
    "#plot_url = py.plot_mpl(fig, filename='mpl-basic-bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NN vs. VB over each round for a tangram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Testing word count function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged = pd.read_csv('/Users/nickimaslan/Desktop/convention_project/tangrams_replication/data/annotated_names/merged.csv')\n",
    "merged.drop(['gameid','time'], axis=1)\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def tokenize(listOfStrings):\n",
    "    mergedStr = []\n",
    "    for wordStr in listOfStrings :   \n",
    "        potato = nltk.word_tokenize(wordStr)\n",
    "        mergedStr.append(potato)\n",
    "    flat = [item for sublist in mergedStr for item in sublist]\n",
    "    return flat\n",
    "#     return list(chain.from_iterable(mergedStr))\n",
    "\n",
    "def tangram(merged, tangram, roundNum ):   ##select tangram and round you want to look at\n",
    "    merged.drop(['gameid','time'], axis=1)\n",
    "    tanMerged = merged[merged['tangram'] == tangram]\n",
    "    tanRound = tanMerged[tanMerged['roundNum'] == roundNum]\n",
    "    return tanRound\n",
    "\n",
    "def tokTan(dataframe):       ##will tokenize the contents grouped by roundNum\n",
    "    wordsCountedC1 = dataframe.groupby(['roundNum'])['contents'].aggregate(tokenize)\n",
    "    return wordsCountedC1\n",
    "\n",
    "def cleanup(listofStrings):  ##only will do one list at a time\n",
    "    listofStrings = [w for w in listofStrings if w not in stopwords]\n",
    "    listofStrings = [w for w in listofStrings if w.isalpha()]\n",
    "    listofStrings = [w for w in listofStrings if len(w) > 2]\n",
    "    listofStrings = [w.lower() for w in listofStrings if w.isalpha()] \n",
    "    listofStrings = [w for w in listofStrings if w not in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', 'the', 'like', 'either' 'ready', 'yeah' 'really,' 'ok', 'looks', 'okay', 'one', 'got', 'go']]\n",
    "    return listofStrings\n",
    "\n",
    "##example with tangram C on round1\n",
    "tangramCr1 = tangram(merged, 'C', '1')\n",
    "tokCr1 = tokTan(tangramCr1)\n",
    "cleanCr1 = cleanup(tokCr1[0])\n",
    "cleanCr1\n",
    "\n",
    "##plot the frequency distribution\n",
    "\n",
    "wordsCounted = merged.groupby(['roundNum'])['contents'].aggregate(tokenize)    #list of words in each round\n",
    "cleaned1 = cleanup(wordsCounted[0])  # cleaned up list of words in round1\n",
    "cleaned2 = cleanup(wordsCounted[1])\n",
    "cleaned3 = cleanup(wordsCounted[2])\n",
    "cleaned4 = cleanup(wordsCounted[3])\n",
    "cleaned5 = cleanup(wordsCounted[4])\n",
    "cleaned6 = cleanup(wordsCounted[5])\n",
    "\n",
    "c = 0\n",
    "while c < 6:\n",
    "    cleanWords = cleanup(wordsCounted[c])\n",
    "    c = c + 1\n",
    "\n",
    "#cleanWords\n",
    "#cleaned2\n",
    "\n",
    "#wordsCounted\n",
    "#fdist1 = nltk.FreqDist(cleaned)\n",
    "#fdist1.plot(30, cumulative=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tangram C vs G graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged = pd.read_csv('/Users/nickimaslan/Desktop/convention_project/tangrams_replication/data/annotated_names/merged.csv')\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def countWords(listOfStrings):\n",
    "    wordCount = 0\n",
    "    for wordStr in listOfStrings :   \n",
    "        potato = nltk.word_tokenize(wordStr) # tokenize it (returns a list of words)\n",
    "        cleanPotato = cleanup(potato)\n",
    "        length = len(potato)   # get length of token list\n",
    "        wordCount = wordCount + length # add that number to wordCount\n",
    "    return wordCount\n",
    "\n",
    "def cleanup(aStr) :\n",
    "    listofStrings = [w for w in aStr if w not in stopwords]\n",
    "    listofStrings = [w for w in listofStrings if w.isalpha()]\n",
    "    listofStrings = [w for w in listofStrings if len(w) > 2]\n",
    "    listofStrings = [w.lower() for w in listofStrings if w.isalpha()] \n",
    "    listofStrings = [w for w in listofStrings if w not in ['like', 'either' 'ready', 'yeah' 'really,' 'ok', 'looks', 'okay', 'one', 'got', 'go']]\n",
    "    return listofStrings\n",
    "\n",
    "tanC = merged[merged['tangram'] == 'C']\n",
    "tanG = merged[merged['tangram'] == 'G']\n",
    "\n",
    "def getMean(dataframe):\n",
    "    meanList = []\n",
    "    for roundNumber in [1,2,3,4,5,6] :\n",
    "        mergeByRound = dataframe[dataframe['roundNum'] == '%d' %roundNumber]\n",
    "        wordsCounted = mergeByRound.groupby(['roundNum'])['contents'].aggregate(countWords)\n",
    "        wordsPerRound = wordsCounted.apply(lambda x: x/(24))\n",
    "        wordMean = wordsPerRound.mean()\n",
    "        meanList.append(wordMean)\n",
    "    return meanList\n",
    "\n",
    "print(getMean(tanC))\n",
    "print(getMean(tanG))\n",
    "# print(tanC)\n",
    "# print(tanG)\n",
    "\n",
    "\n",
    "\n",
    "def getStDev(dataframe):\n",
    "    stdList = []\n",
    "    for roundNumber in [1,2,3,4,5,6] :\n",
    "        mergeByRound = dataframe[dataframe['roundNum'] == '%d' %roundNumber]\n",
    "        wordsCounted = mergeByRound.groupby(['roundNum','gameid'])['contents'].aggregate(countWords)\n",
    "        wordsPerRound = wordsCounted.apply(lambda x: x/(1))\n",
    "        std = wordsPerRound.std()\n",
    "        stdList.append(std)\n",
    "    return stdList\n",
    "\n",
    "\n",
    "\n",
    "##df for tangram C\n",
    "tanC = merged[merged['tangram'] == 'C']\n",
    "wordsCountedC = tanC.groupby(['roundNum','gameid'])['contents'].aggregate(countWords)\n",
    "meanC = getMean(tanC)\n",
    "stErrorC = getStDev(tanC)/np.sqrt(24)\n",
    "print(meanC)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# ##df for tangram G\n",
    "tanG = merged[merged['tangram'] == 'G']\n",
    "wordsCountedG = tanG.groupby(['roundNum', 'gameid'])['contents'].aggregate(countWords)\n",
    "meanG = getMean(tanG)\n",
    "stErrorG = getStDev(tanG)/np.sqrt(24)\n",
    "stErrorG\n",
    "print(meanG)\n",
    "\n",
    "##plot it\n",
    "##data to be plotted\n",
    "# wordsPerRound = wordsCounted.apply(lambda x: x/(12*24))\n",
    "rounds = [1,2,3,4,5,6]\n",
    "\n",
    "##error data\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "\n",
    "##plotting\n",
    "# fig = plt.figure(figsize=(6, 6))\n",
    "# axes = fig.add_subplot(111)\n",
    "plt.plot(rounds, meanG, color='red')\n",
    "plt.plot(rounds, meanC, color='blue')\n",
    "# \n",
    "##plot error bars\n",
    "plt.errorbar(rounds,meanG,yerr=stErrorG, linestyle=\"None\", color=\"red\")\n",
    "plt.errorbar(rounds,meanC,yerr=stErrorC, linestyle=\"None\", color=\"blue\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#configure x and y axes\n",
    "plt.ylim([0,40])\n",
    "plt.xlim([0,7])\n",
    "plt.title('Tangram C vs. G words per round', size=15)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Trials', size=14)\n",
    "plt.ylabel('Average amount of words players used', size=14)\n",
    "\n",
    "##save plot\n",
    "plt.savefig(\"/Users/nickimaslan/Desktop/GvsCTangrams.png\", bbox_inches='tight')\n",
    "\n",
    "##show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg Director word count for each tangram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged = pd.read_csv('/Users/nickimaslan/Desktop/convention_project/tangrams_replication/data/annotated_names/merged.csv')\n",
    "from itertools import chain\n",
    "def countWords(listOfStrings):\n",
    "    wordCount = 0\n",
    "    for wordStr in listOfStrings :   \n",
    "        potato = nltk.word_tokenize(wordStr) # tokenize it (returns a list of words)\n",
    "        length = len(potato)   # get length of token list\n",
    "        wordCount = wordCount + length # add that number to wordCount\n",
    "    return wordCount\n",
    "        \n",
    "# merged.groupby(['tangram'])['roundNum'].apply(plus1)\n",
    "merged = merged[merged['sender'] == 'director']\n",
    "merged = merged[merged['tangram'] != '0']\n",
    "merged = merged[merged['tangram'] != '10']\n",
    "merged = merged[merged['tangram'] != ':']\n",
    "\n",
    "def getStDev(dataframe):\n",
    "    stdList = []\n",
    "    for roundNumber in [1,2,3,4,5,6] :\n",
    "        mergeByRound = merged[merged['roundNum'] == '%d' %roundNumber]\n",
    "        wordsCounted = mergeByRound.groupby(['roundNum','gameid'])['contents'].aggregate(countWords)\n",
    "        wordsPerRound = wordsCounted.apply(lambda x: x/(12))\n",
    "        std = wordsPerRound.std()\n",
    "        stdList.append(std)\n",
    "    return stdList\n",
    "\n",
    "error = np.sqrt(24)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "wordsCounted = merged.groupby(['roundNum'])['contents'].aggregate(countWords)\n",
    "\n",
    "##data to be plotted\n",
    "wordsPerRound = wordsCounted.apply(lambda x: x/(12*24))\n",
    "rounds = [1,2,3,4,5,6]\n",
    "\n",
    "##error data\n",
    "stdErrorList = getStDev(merged)/error\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "\n",
    "##plotting\n",
    "# fig = plt.figure(figsize=(6, 6))\n",
    "# axes = fig.add_subplot(111)\n",
    "plt.plot(rounds, wordsPerRound)\n",
    "\n",
    "##plot error bars\n",
    "plt.errorbar(rounds,wordsPerRound,yerr=stdList, linestyle=\"None\", color=\"green\")\n",
    "\n",
    "#configure x and y axes\n",
    "plt.ylim([0,20])\n",
    "plt.xlim([0,7])\n",
    "plt.title('Avg director word count for each tangram', size=15)\n",
    "plt.grid(True)\n",
    "plt.xlabel('trials', size=14)\n",
    "plt.ylabel('mean number words (by director) per figure', size=14)\n",
    "\n",
    "##save plot\n",
    "plt.savefig(\"/Users/nickimaslan/Desktop/avgWordsTallFont.png\", bbox_inches='tight')\n",
    "\n",
    "##show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged = pd.read_csv('/Users/nickimaslan/Desktop/convention_project/tangrams_replication/data/annotated_names/merged.csv')\n",
    "# merged.ix[0:, ['contents', 'tangram']]\n",
    "tangramMerge = merged[merged['tangram'] != '0']\n",
    "tangram = merged[merged['tangram'] == 'G']\n",
    "tangramRound = tangram[tangram['roundNum'] == '6']\n",
    "contents = tangramRound.ix[0:, ['contents']]\n",
    "contents\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
