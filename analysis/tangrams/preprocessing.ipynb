{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import lots of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pylab as pyl\n",
    "import nltk as nltk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "%matplotlib inline\n",
    "#enable longer display\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import annotated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d_raw = pd.read_csv('../../data/tangrams/old/oldTangrams.csv')\n",
    "\n",
    "# Drop time column\n",
    "d = (d_raw\n",
    "    .copy()\n",
    "    .drop('time', 1)\n",
    "    .query('tangram != \"0\"')\n",
    "    .query('tangram != \"*\"'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d['tokens'] = [[word for word in nltk.word_tokenize(sentence.lower()) if word.isalpha()]\n",
    "               for sentence in d['contents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get number of words used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d['numWords'] = [pd.value_counts(words).sum() for words in d['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 1: Generate file for POS analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d['pos'] = [[pos for (key, pos) in nltk.pos_tag(rowTokens, tagset = 'universal')] \n",
    "            for rowTokens in d['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all unique POS labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posSet = set({})\n",
    "for row in d['pos'] :\n",
    "    for pos in row :\n",
    "        posSet.add(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get counts for each POS label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pos in posSet :\n",
    "    colName = pos + \"num\"\n",
    "    d[colName] = [posList.count(pos) for posList in d['pos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to csv for plotting in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(d.drop([\"pos\", \"contents\", \"tokens\"], 1)\n",
    " .to_csv(\"posTagged.csv\", index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 2: Calculate indicator words for tangrams/rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, get list of words in first round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter down to first round\n",
    "d_round1 = d[d['roundNum'] == 1]\n",
    "\n",
    "# Pull out all tokens and collapse into count dict\n",
    "tokenDict = Counter([item for sublist in d_round1['tokens'].tolist()\n",
    "                     for item in sublist])\n",
    "\n",
    "# Pull out all words that occur more than once\n",
    "wordList = [word for (word,count) in tokenDict.items() if count > 1]\n",
    "print(wordList[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all game ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gameidList = pd.unique(d.gameid.ravel()).tolist()\n",
    "print(gameidList[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all tangram names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tangramList = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
    "print(tangramList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to select words & counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getWordCounts(df, gameid, roundNum, tangram = None) :\n",
    "    roundCond = 'roundNum == ' + roundNum\n",
    "    gameidCond = 'gameid == \"' + gameid + '\"'\n",
    "    if(tangram is not None) :\n",
    "        tangramCond = 'tangram == \"' + tangram + '\"'\n",
    "        cond = \" and \".join((roundCond, gameidCond, tangramCond))\n",
    "    else :\n",
    "        cond = \" and \".join((roundCond, gameidCond))\n",
    "    relevantRow = df.query(cond)\n",
    "    return Counter([item for sublist in relevantRow['tokens'].tolist() \n",
    "                    for item in sublist])\n",
    "\n",
    "#creates mini dataframe that grabs the words used in round n for a given tangram and gameid\n",
    "def selectTangramRoundWords(df, tangram, roundNum, gameid):\n",
    "    wordCounts = getWordCounts(df, gameid, roundNum, tangram)\n",
    "    return wordCounts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to compute PMIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns a table with the all words above 0 PMI and their counts for a given tangram\n",
    "#calculate the probability for words given tangram A ------ p(x|y)\n",
    "def makeMyPMI(df, tangram, roundNum, gameid, totals):\n",
    "\n",
    "    # count words w/in tangram\n",
    "    tangramCounts = getWordCounts(df, gameid, roundNum, tangram)\n",
    "\n",
    "    #total number of words \n",
    "    tangramNumWords = (1 if sum(tangramCounts.values()) == 0 \n",
    "                       else sum(tangramCounts.values()))\n",
    "\n",
    "    #dataframe to compare \n",
    "    indicatorDF = pd.merge(pd.DataFrame(tangramCounts.items(), columns=['word', 'count']),\n",
    "                           pd.DataFrame(totals[\"counts\"].items(), columns=['word', 'totalCount']),\n",
    "                           on='word', how = 'inner')\n",
    "\n",
    "    #calculate PMI without log first. Having trouble with float issues. \n",
    "    indicatorDF['roughPMI'] = ((indicatorDF['count']/tangramNumWords)\n",
    "                                / (indicatorDF['totalCount']/totals[\"numWords\"]))\n",
    "    indicatorDF['logPMI'] = [math.log10(num) for num in indicatorDF['roughPMI']]\n",
    "    \n",
    "    #remove column rough PMI\n",
    "    indicatorDF = indicatorDF.drop('roughPMI', 1)\n",
    "    \n",
    "    return indicatorDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('matchAndPMI.csv', 'ab') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['word', 'match', 'pmi', 'total'])\n",
    "    for word in wordList :\n",
    "        print(word)\n",
    "        pmi = 0\n",
    "        match = 0\n",
    "        total = 0\n",
    "        for gameid in gameidList:  \n",
    "            memoizedCounts = {}\n",
    "            for tangram in tangramList:\n",
    "                round1WordList = selectTangramRoundWords(d, tangram, \"1\", gameid)\n",
    "                total = total + 1 if word in round1WordList else total\n",
    "                if word in round1WordList :\n",
    "                    if \"counts\" not in memoizedCounts : \n",
    "                        memoizedCounts[\"counts\"] = getWordCounts(d, gameid, \"1\")\n",
    "                        memoizedCounts[\"numWords\"] = float(sum(memoizedCounts[\"counts\"].values()))\n",
    "                    PMI_df = makeMyPMI(d, tangram, \"1\", gameid, memoizedCounts)\n",
    "                    pmi = pmi + PMI_df[PMI_df['word'] == word]['logPMI'].tolist()[0]\n",
    "                    round6WordList = selectTangramRoundWords(d, tangram, \"6\", gameid)\n",
    "                    match = (match + 1 if (word in round1WordList and word in round6WordList)\n",
    "                             else match)\n",
    "        writer.writerow([word, float(match) / float(total), pmi/total, total])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#https://en.wikipedia.org/wiki/Pointwise_mutual_information\n",
    "\n",
    "#returns a table with the all words about 0 PMI and their counts for a given tangram\n",
    "#calculate the probability for words given tangram A ------ p(x|y)\n",
    "\n",
    "# Note that we're reconstructing totalCounts for every tangram... \n",
    "def makeMyPMI(tangram, roundNum, gameid):\n",
    "\n",
    "    # count words w/in tangram\n",
    "    tangramCounts = getWordCounts(test2, gameid, roundNum, tangram)\n",
    "    totalCounts = getWordCounts(test2, gameid, roundNum)\n",
    "\n",
    "    #total number of words \n",
    "    tangramNumWords = (1 if sum(tangramCounts.values()) == 0 \n",
    "                       else sum(tangramCounts.values()))\n",
    "    totalNumWords = float(sum(totalCounts.values()))\n",
    "\n",
    "    #dataframe to compare \n",
    "    indicatorDF = pd.merge(pd.DataFrame(tangramCounts.items(), columns=['word', 'count']),\n",
    "                           pd.DataFrame(totalCounts.items(), columns=['word', 'totalCount']),\n",
    "                           on='word', how = 'inner')\n",
    "\n",
    "    #calculate PMI without log first. Having trouble with float issues. \n",
    "    indicatorDF['roughPMI'] = ((indicatorDF['count']/tangramNumWords)\n",
    "                                / (indicatorDF['totalCount']/totalNumWords))\n",
    "    indicatorDF['logPMI'] = [math.log10(num) for num in indicatorDF['roughPMI']]\n",
    "    \n",
    "    #indicatorAdf\n",
    "    highPMI = indicatorDF[indicatorDF['logPMI'] > -1]\n",
    "    highPMI = highPMI.sort(['logPMI'], ascending=0)\n",
    "    \n",
    "    #insert tangram and roundNum and gameid\n",
    "    highPMI['gameid'] = gameid\n",
    "    highPMI['tangram'] = tangram\n",
    "    highPMI['roundNum'] = roundNum\n",
    "    \n",
    "    #rearragne columns\n",
    "    cols = highPMI.columns.tolist()\n",
    "    cols = cols[-3:] + cols[:-3]\n",
    "    highPMI = highPMI[cols]\n",
    "    \n",
    "    #remove column rough PMI\n",
    "    highPMI = highPMI.drop('roughPMI', 1)\n",
    "    \n",
    "    return highPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grab words with highestPMI\n",
    "def highestPMI(tangram, roundNum, gameid):\n",
    "    PMIdf = makeMyPMI(tangram, roundNum, gameid)\n",
    "    #if PMIdf has words, pull out max values, it is empty return it as is\n",
    "    if len(PMIdf.index) > 0:\n",
    "        PMI_values = PMIdf.logPMI.unique()\n",
    "        maxPMI = PMI_values.max()\n",
    "        PMIdf = PMIdf.loc[PMIdf['logPMI'] == maxPMI]\n",
    "        #just return word column\n",
    "        PMIdf = PMIdf[['word']]\n",
    "        return PMIdf\n",
    "    #if PMIdf is empty, return it as is\n",
    "    else: \n",
    "        return PMIdf\n",
    "\n",
    "#function to randomly sample a word from the list of words used by a group for a given tangram on round 1\n",
    "def randomWord(wordDataframe):\n",
    "    if len(wordDataframe.index) == 0:\n",
    "        return wordDataframe\n",
    "    else: \n",
    "        rows = np.random.choice(wordDataframe.index.values, 1)\n",
    "        randomSample = wordDataframe.ix[rows]\n",
    "        return randomSample\n",
    "\n",
    "#create dataframe of words used in round 6 and the words that had the highest pmi in round 1\n",
    "def mergePmiRounds(tangram, gameid):\n",
    "    round1 = highestPMI(tangram, 1, gameid)\n",
    "    round6 = selectTangramRoundWords(tangram, 6, gameid)\n",
    "    innerMerge = pd.merge(round1, round6, on = 'word', how='inner')\n",
    "    return innerMerge\n",
    "\n",
    "# measures if the words in round 6 had a highPMI in round 1. If they do, return a 1. If not, return 0. \n",
    "def continuityCount(innerMerge):\n",
    "    continuityCount = 0 \n",
    "    if len(innerMerge.index) > 0:\n",
    "        continuityCount += 1\n",
    "    else:\n",
    "        continuityCount = 0\n",
    "    return continuityCount\n",
    "\n",
    "#takes in a string and turns it into a list\n",
    "def listify(word):\n",
    "    l = []\n",
    "    l.append(word)\n",
    "    return l\n",
    "\n",
    "#given a pos tag like this: [('person', 'NN')], determine if the word is a noun\n",
    "def isWordNoun(posTag):\n",
    "    if posTag[0][1] == 'NN':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#function which only keeps nouns in dataframe word column\n",
    "def filterForNoun(df):\n",
    "    df['token'] = [listify(word) for word in df['word']]\n",
    "    df['pos'] = [nltk.pos_tag(token) for token in df['token']]\n",
    "    df['noun'] = [isWordNoun(postag) for postag in df['pos']]\n",
    "    df = df[df.noun == True]\n",
    "    df = df[['word']]\n",
    "    return df\n",
    "\n",
    "\n",
    "def PMImatches(highPMI_df, round6_df):\n",
    "    if len(highPMI_df.index) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        highPMI_wordList = highPMI_df['word'].tolist()\n",
    "        length = len(highPMI_wordList)\n",
    "        round6_wordList = round6_df['word'].tolist()\n",
    "        count = 0\n",
    "        for i in range(length):\n",
    "            if highPMI_wordList[i] in round6_wordList:\n",
    "                count += 1\n",
    "            else:\n",
    "                count += 0\n",
    "        return float(count)/length\n",
    "    \n",
    "def nullmatches(round1_df, round6_df):\n",
    "    if len(round1_df.index) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        random_round1_df = randomWord(round1_df)\n",
    "        random_round1_list = random_round1_df['word'].tolist()\n",
    "        round6_list = round6_df['word'].tolist()\n",
    "        count = 0\n",
    "        if random_round1_list[0] in round6_list:\n",
    "             return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "\n",
    "#picks a highest PMI word from round 1 (for tangram/gameid) and sees if it is used in round 6. Calculates proportion of this over 288 tangram/gameid situations\n",
    "def totalContinuity():\n",
    "    totalContinuity = 0\n",
    "    for gameid in gameidList:    \n",
    "        for tangram in tangramList:\n",
    "            highPMIwordList = highestPMI(tangram, 1, gameid)\n",
    "            #random_highPMIWord = randomWord(highPMIwordList)\n",
    "            round6WordList = selectTangramRoundWords(tangram, 6, gameid)\n",
    "            score = PMImatches(highPMIwordList, round6WordList)\n",
    "            totalContinuity = totalContinuity + score\n",
    "    return float(totalContinuity)/288\n",
    "\n",
    "\n",
    "#totalContinuity()\n",
    "\n",
    "#picks a random noun from round 1 (for tangram/gameid) and sees if it is used in round 6. Calculates proportion, given that is does this 288 times\n",
    "def nullDistribution():\n",
    "    totalContinuity = 0\n",
    "    for gameid in gameidList:    \n",
    "        for tangram in tangramList:\n",
    "            round1tangramWordList = selectTangramRoundWords(tangram, \"1\", gameid)\n",
    "#             nounOnlyWordList = filterForNoun(round1tangramWordList)\n",
    "#             random_round1Word = randomWord(nounOnlyWordList)\n",
    "#             random_round1Word = randomWord(round1tangramWordList)\n",
    "            round6WordList = selectTangramRoundWords(tangram, \"6\", gameid)\n",
    "            score = nullmatches(round1tangramWordList, round6WordList) \n",
    "            totalContinuity = totalContinuity +  score\n",
    "    return float(totalContinuity)/288\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# tester = selectTangramRoundWords('A', 1, '0215-4')\n",
    "# tester = filterForNoun(tester)\n",
    "# tester\n",
    "\n",
    "PMI_distribution = []\n",
    "def longDistribution():\n",
    "    for i in range(100):\n",
    "        proportion = nullDistribution() \n",
    "        PMI_distribution.append(proportion)\n",
    "    return PMI_distribution\n",
    "\n",
    "# PMI_distribution_lists = [0.4305555555555556, 0.4513888888888889]\n",
    "# null_distribution_lists = [0.2847222222222222, 0.2708333333333333]\n",
    "# null_noun_distribution_lists = [0.3611111111111111]\n",
    "#nullDistribution()\n",
    "#totalContinuity()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# round1Test = highestPMI('E', 1, '0215-4')\n",
    "# round6Test = selectTangramRoundWords('E', 6, '0215-4')\n",
    "# nullmatches(round1Test, round6Test)\n",
    "\n",
    "\n",
    "# 'pup' in [ 'dog', 'kitten']\n",
    "# randomPMI['word'].tolist()[0] in round6Test['word'].tolist()\n",
    "# round6Test['word'].tolist()\n",
    "    \n",
    "# PMImatches(round1Test, round6Test)\n",
    "# highPMITest\n",
    "# round6Test\n",
    "# nullDistribution()\n",
    "# nullDistributionLongList = longDistribution()\n",
    "\n",
    "\n",
    "\n",
    "#longDistribution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nullDistributionNums = [0.2013888888888889,\n",
    " 0.19444444444444445,\n",
    " 0.1423611111111111,\n",
    " 0.1597222222222222,\n",
    " 0.13541666666666666,\n",
    " 0.1527777777777778,\n",
    " 0.13194444444444445,\n",
    " 0.17708333333333334,\n",
    " 0.1388888888888889,\n",
    " 0.1597222222222222,\n",
    " 0.1597222222222222,\n",
    " 0.16666666666666666,\n",
    " 0.1423611111111111,\n",
    " 0.21180555555555555,\n",
    " 0.1527777777777778,\n",
    " 0.16319444444444445,\n",
    " 0.1840277777777778,\n",
    " 0.1423611111111111,\n",
    " 0.18055555555555555,\n",
    " 0.15625,\n",
    " 0.17708333333333334,\n",
    " 0.1701388888888889,\n",
    " 0.19444444444444445,\n",
    " 0.1701388888888889,\n",
    " 0.16666666666666666,\n",
    " 0.1701388888888889,\n",
    " 0.1597222222222222,\n",
    " 0.1527777777777778,\n",
    " 0.14930555555555555,\n",
    " 0.1388888888888889,\n",
    " 0.2048611111111111,\n",
    " 0.16666666666666666,\n",
    " 0.14583333333333334,\n",
    " 0.1736111111111111,\n",
    " 0.16666666666666666,\n",
    " 0.16666666666666666,\n",
    " 0.16666666666666666,\n",
    " 0.15625,\n",
    " 0.1388888888888889,\n",
    " 0.1423611111111111,\n",
    " 0.1527777777777778,\n",
    " 0.1597222222222222,\n",
    " 0.2048611111111111,\n",
    " 0.15625,\n",
    " 0.15625,\n",
    " 0.1597222222222222,\n",
    " 0.1597222222222222,\n",
    " 0.13541666666666666,\n",
    " 0.1527777777777778,\n",
    " 0.16319444444444445,\n",
    " 0.16666666666666666,\n",
    " 0.1423611111111111,\n",
    " 0.16666666666666666,\n",
    " 0.1736111111111111,\n",
    " 0.1388888888888889,\n",
    " 0.18055555555555555,\n",
    " 0.14930555555555555,\n",
    " 0.15625,\n",
    " 0.1701388888888889,\n",
    " 0.14583333333333334,\n",
    " 0.15625,\n",
    " 0.18055555555555555,\n",
    " 0.1597222222222222,\n",
    " 0.1597222222222222,\n",
    " 0.17708333333333334,\n",
    " 0.13541666666666666,\n",
    " 0.14583333333333334,\n",
    " 0.1284722222222222,\n",
    " 0.1527777777777778,\n",
    " 0.2048611111111111, \n",
    " 0.1527777777777778,\n",
    " 0.1527777777777778,\n",
    " 0.1527777777777778,\n",
    " 0.1423611111111111,\n",
    " 0.1597222222222222,\n",
    " 0.1388888888888889,\n",
    " 0.1701388888888889,\n",
    " 0.1597222222222222,\n",
    " 0.1597222222222222,\n",
    " 0.17708333333333334,\n",
    " 0.16319444444444445,\n",
    " 0.14930555555555555,\n",
    " 0.1597222222222222,\n",
    " 0.1527777777777778,\n",
    " 0.14930555555555555,\n",
    " 0.1423611111111111,\n",
    " 0.15625,\n",
    " 0.1736111111111111,\n",
    " 0.1597222222222222,\n",
    " 0.1701388888888889,\n",
    " 0.1527777777777778,\n",
    " 0.1423611111111111,\n",
    " 0.15625,\n",
    " 0.1388888888888889,\n",
    " 0.19791666666666666,\n",
    " 0.14583333333333334,\n",
    " 0.17708333333333334,\n",
    " 0.1388888888888889,\n",
    " 0.1909722222222222,\n",
    " 0.14583333333333334,\n",
    " 0.1875,\n",
    " 0.16666666666666666,\n",
    " 0.19444444444444445,\n",
    " 0.16319444444444445,\n",
    " 0.15625,\n",
    " 0.1527777777777778,\n",
    " 0.1701388888888889,\n",
    " 0.12152777777777778,\n",
    " 0.1701388888888889,\n",
    " 0.13194444444444445,\n",
    " 0.1597222222222222,\n",
    " 0.1388888888888889,\n",
    " 0.1736111111111111,\n",
    " 0.1527777777777778,\n",
    " 0.14930555555555555,\n",
    " 0.16319444444444445,\n",
    " 0.1527777777777778,\n",
    " 0.14583333333333334,\n",
    " 0.13541666666666666,\n",
    " 0.1875,\n",
    " 0.1597222222222222,\n",
    " 0.16666666666666666,\n",
    " 0.1909722222222222,\n",
    " 0.1597222222222222,\n",
    " 0.16319444444444445,\n",
    " 0.14930555555555555,\n",
    " 0.1909722222222222,\n",
    " 0.1527777777777778,\n",
    " 0.14930555555555555,\n",
    " 0.1527777777777778,\n",
    " 0.1736111111111111,\n",
    " 0.18055555555555555,\n",
    " 0.1423611111111111,\n",
    " 0.15625,\n",
    " 0.1840277777777778,\n",
    " 0.1388888888888889,\n",
    " 0.16319444444444445,\n",
    " 0.14930555555555555,\n",
    " 0.16319444444444445,\n",
    " 0.16319444444444445,\n",
    " 0.1840277777777778,\n",
    " 0.19791666666666666,\n",
    " 0.1597222222222222,\n",
    " 0.1388888888888889,\n",
    " 0.1736111111111111,\n",
    " 0.1423611111111111,\n",
    " 0.13541666666666666,\n",
    " 0.15625,\n",
    " 0.1875,\n",
    " 0.1597222222222222,\n",
    " 0.16319444444444445,\n",
    " 0.1597222222222222,\n",
    " 0.1423611111111111,\n",
    " 0.1597222222222222,\n",
    " 0.1875,\n",
    " 0.13194444444444445,\n",
    " 0.16319444444444445,\n",
    " 0.1423611111111111,\n",
    " 0.16666666666666666,\n",
    " 0.1388888888888889,\n",
    " 0.14930555555555555,\n",
    " 0.1527777777777778,\n",
    " 0.16319444444444445,\n",
    " 0.1423611111111111,\n",
    " 0.1701388888888889,\n",
    " 0.1388888888888889,\n",
    " 0.15625,\n",
    " 0.17708333333333334,\n",
    " 0.19444444444444445,\n",
    " 0.1736111111111111,\n",
    " 0.1701388888888889,\n",
    " 0.14583333333333334,\n",
    " 0.16319444444444445,\n",
    " 0.17708333333333334,\n",
    " 0.14583333333333334,\n",
    " 0.1875,\n",
    " 0.16666666666666666,\n",
    " 0.17708333333333334,\n",
    " 0.16666666666666666,\n",
    " 0.1527777777777778,\n",
    " 0.1736111111111111,\n",
    " 0.16666666666666666,\n",
    " 0.11805555555555555,\n",
    " 0.18055555555555555,\n",
    " 0.16666666666666666,\n",
    " 0.1701388888888889,\n",
    " 0.1388888888888889,\n",
    " 0.16666666666666666,\n",
    " 0.14930555555555555,\n",
    " 0.1909722222222222,\n",
    " 0.17708333333333334,\n",
    " 0.125,\n",
    " 0.15625,\n",
    " 0.1701388888888889,\n",
    " 0.14930555555555555,\n",
    " 0.11805555555555555,\n",
    " 0.1597222222222222,\n",
    " 0.14583333333333334,\n",
    " 0.16666666666666666,\n",
    " 0.16319444444444445]\n",
    "\n",
    "\n",
    "#nullDistributionNums.to_csv(\"nullDistributionNums.csv\")  \n",
    "plt.hist(nullDistributionNums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Find confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "# import scipy as sp\n",
    "# import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(nullDistributionNums, confidence=0.95):\n",
    "    a = 1.0*np.array(nullDistributionNums)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame\n",
    "df1 = df1({'test_set': nullDistributionNums})\n",
    "df1\n",
    "\n",
    "df1.to_csv(\"nullDistributionNums.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Filtering for nouns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creat dictionary that contains tangram, roundNum, word, and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfForDict = test2.copy()\n",
    "dfForDict = dfForDict[20:500]\n",
    "\n",
    "#http://stackoverflow.com/questions/16333296/how-do-you-create-nested-dict-in-python\n",
    "#set up the nested dictionaries\n",
    "tangramDict = {}\n",
    "tangramDict['tangram'] = {}\n",
    "tangramDict['tangram']['roundNum'] = {}\n",
    "tangramDict['tangram']['roundNum']['word'] = 'count'\n",
    "tangramDict\n",
    "\n",
    "#populate the dictionary \n",
    "\n",
    "#http://stackoverflow.com/questions/635483/what-is-the-best-way-to-implement-nested-dictionaries-in-python\n",
    "\n",
    "\n",
    "dfForDict = dfForDict[['roundNum', 'tangram', 'tokens']]\n",
    "dfForDict = dfForDict.sort(['roundNum', 'tangram'], ascending = [True, True])\n",
    "#rearrange columns\n",
    "cols = dfForDict.columns.tolist()\n",
    "cols = ['tangram', 'roundNum', 'tokens']\n",
    "dfForDict = dfForDict[cols]\n",
    "#dfForDict = dfForDict.groupby('roundNum')\n",
    "# dfForDict = dfForDict[2:500]\n",
    "\n",
    "\n",
    "import pprint\n",
    "\n",
    "class Vividict(dict):\n",
    "    def __missing__(self, key):\n",
    "        value = self[key] = type(self)()\n",
    "        return value\n",
    "    \n",
    "d = Vividict()\n",
    "\n",
    "# d['foo']['bar']\n",
    "# d['foo']['baz']\n",
    "# d['fizz']['buzz']\n",
    "# d['primary']['secondary']['tertiary']['quaternary']\n",
    "\n",
    "\n",
    "\n",
    "pprint.pprint(d)\n",
    "\n",
    "#http://stackoverflow.com/questions/18695605/python-pandas-dataframe-to-dictionary\n",
    "\n",
    "#{g: f['contents'].tolist() for f,g in dfForDict.groupby(\"tangram\") for k,g in dfForDict.groupby(\"roundNum\")}\n",
    "\n",
    "#{k: g[\"value\"].tolist() for k,g in ptest.groupby(\"id\")}\n",
    "\n",
    "\n",
    "def retro_dictify(frame):\n",
    "    d = {}\n",
    "    for row in frame.values:\n",
    "        here = d\n",
    "        for elem in row[:-2]:\n",
    "            if elem not in here:\n",
    "                here[elem] = {}\n",
    "            here = here[elem]\n",
    "        here[row[-2]] = row[-1]\n",
    "    return d\n",
    "\n",
    "retro_dictify(dfForDict)\n",
    "\n",
    "\n",
    "\n",
    "# d = defaultdict(int)\n",
    "# for word in bigWordList :\n",
    "#   for tangram in tangrams :\n",
    "#     for roundNum in roundNums :\n",
    "#       d[tangram + ‘,’ + str(roundNum) + ‘,’ + word] += \n",
    "#countOccurences(word, tangram, roundNum)\n",
    "\n",
    "# writer = csv.writer(open(’tangramWordCounts.csv', 'wb'))\n",
    "# for key, value in d.items():\n",
    "#   writer.writerow([key, value])\n",
    "\n",
    "#dfForDict.groupby()\n",
    "\n",
    "#[f(x) for x in list]\n",
    "\n",
    "dfForDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#use highPMI list to filter words for tangrams over the next rounds\n",
    "#need list of words and their frequency for each round\n",
    "#need 6 dictionaries/frequencies merged by the highPMI words\n",
    "\n",
    "#the dataframe with all tangrams and all rounds\n",
    "bigFrame = test2.copy()\n",
    "#bigFrameTangram = bigFrame[bigFrame.tangram == 'A']\n",
    "\n",
    "#cumWordsAndCounts = highPMI\n",
    "\n",
    "def createFrequencyTable(roundNum, tangram):\n",
    "    #filter for the tangram desired\n",
    "    bigFrameTangram = bigFrame[bigFrame.tangram == tangram]\n",
    "    bigFrameTangram = bigFrame[bigFrame.roundNum == roundNum]\n",
    "    cumWordsAndCounts = makeMyPMI(tangram)\n",
    "    #print cumWordsAndCounts\n",
    "    #go from 2-6 because round1 is included with cumWordsAndCounts \n",
    "    #for roundNum in [2,3,4,5,6]:\n",
    "    #filter by roundNum\n",
    "    bigFrameTangram = bigFrameTangram[bigFrameTangram.roundNum == roundNum]\n",
    "\n",
    "    #bigDictionary turns all of the tokens used to talk about tangram A over round into a dictionary\n",
    "    smallDictionary = bigFrameTangram['tokens'].tolist()\n",
    "    smallDictionary = [item for sublist in smallDictionary for item in sublist]\n",
    "    #get dictionary counter for words used for tangram A\n",
    "    smallDictionary = Counter(smallDictionary)\n",
    "\n",
    "    #convert to normal dictionary in order to pull out counts more easily\n",
    "    #smallDictionary = smallDictionary.items() \n",
    "\n",
    "    #turn dictionary with counts into dataframe\n",
    "    #dataframe to look at words and their counts for tangram A in round 1\n",
    "    smallWordsAndCounts = pd.DataFrame(smallDictionary.items(), columns=['word', 'count'])\n",
    "    #smallWordsAndCount['tangram'] = tan\n",
    "    #dataframe which will contain words and the frequencies of them on rounds 1 through 6\n",
    "    #print cumWordsAndCounts[:5][:5]\n",
    "    #cumWordsAndCounts = pd.concat([cumWordsAndCounts, smallWordsAndCounts])\n",
    "    #print cumWordsAndCounts[:5][:5]\n",
    "\n",
    "    #reset bigFrame so we can go to the next roundNum\n",
    "    #bigFrameTangram = bigFrame[bigFrame.tangram == tangram]\n",
    "\n",
    "    return smallWordsAndCounts\n",
    "    \n",
    "\n",
    "wordFrequency_A = createFrequencyTable(2, 'A')\n",
    "\n",
    "wordFrequency_A\n",
    "\n",
    "# d = defaultdict(int)\n",
    "# for word in bigWordList :\n",
    "#   for tangram in tangrams :\n",
    "#     for roundNum in roundNums :\n",
    "#       d[tangram + ‘,’ + str(roundNum) + ‘,’ + word] += countOccurences(word, tangram, roundNum)\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "# allTangramsFreqs = pd.DataFrame()\n",
    "# for tangram in ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']:\n",
    "#     #creates the words and frequencies over rounds df for one tangram\n",
    "#     oneTangramFreq = createFrequencyTable(tangram)\n",
    "#     #joins all words and their frequencies over rounds for each tangram\n",
    "#     allTangramsFreqs = pd.concat([allTangramsFreqs, oneTangramFreq], axis=1)\n",
    "\n",
    "# #change the column names to tangram letter and correct round numbers\n",
    "# allTangramsFreqs.columns = ['A', '1', '2', '3', '4', '5', '6', 'B', '1', '2', '3', '4', '5', '6', \n",
    "#                            'C', '1', '2', '3', '4', '5', '6', 'D', '1', '2', '3', '4', '5', '6', \n",
    "#                            'E', '1', '2', '3', '4', '5', '6', 'F', '1', '2', '3', '4', '5', '6', \n",
    "#                            'G', '1', '2', '3', '4', '5', '6', 'H', '1', '2', '3', '4', '5', '6', \n",
    "#                            'I', '1', '2', '3', '4', '5', '6', 'J', '1', '2', '3', '4', '5', '6',\n",
    "#                            'K', '1', '2', '3', '4', '5', '6', 'L', '1', '2', '3', '4', '5', '6']\n",
    "# allTangramsFreqs.to_csv(\"allTangramsFreqs.csv\")   \n",
    "\n",
    "    \n",
    "\n",
    "len(pd.unique(test1.gameid.ravel()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Occurances function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use highPMI list to filter words for tangrams over the next rounds\n",
    "#need list of words and their frequency for each round\n",
    "#need 6 dictionaries/frequencies merged by the highPMI words\n",
    "\n",
    "#the dataframe with all tangrams and all rounds\n",
    "bigFrame = test2.copy()\n",
    "\n",
    "def createFrequencyTable(tangram, roundNum):\n",
    "    #filter for the tangram desired\n",
    "    myDictDf = bigFrame[bigFrame.tangram == tangram]\n",
    "    myDictDf = myDictDf[myDictDf.roundNum == roundNum]\n",
    "\n",
    "    #bigDictionary turns all of the tokens used to talk about tangram A over round into a dictionary\n",
    "    smallDictionary = myDictDf['tokens'].tolist()\n",
    "    smallDictionary = [item for sublist in smallDictionary for item in sublist]\n",
    "    #get dictionary counter for words used for tangram A\n",
    "    smallDictionary = Counter(smallDictionary)\n",
    "\n",
    "    #turn dictionary with counts into dataframe\n",
    "    #dataframe to look at words and their counts for tangram A in round 1\n",
    "    smallWordsAndCounts = pd.DataFrame(smallDictionary.items(), columns=['word', 'count'])\n",
    "\n",
    "    return smallWordsAndCounts\n",
    "    \n",
    "\n",
    "createFrequencyTable('A', 3)\n",
    "\n",
    "d = defaultdict(int)\n",
    "for word in bigWordList :\n",
    "  for tangram in tangrams :\n",
    "    for roundNum in roundNums :\n",
    "      d[tangram + ‘,’ + str(roundNum) + ‘,’ + word] += countOccurences(word, tangram, roundNum)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Type and token probabilities over rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#don't know what this is not working right now :/\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "#https://en.wikipedia.org/wiki/Pointwise_mutual_information\n",
    "\n",
    "\n",
    "#calculate the probability for words given tangram A ------ p(x|y)\n",
    "#indic is dataframe just looking at tangram A over round 1\n",
    "wordList = test2.copy()\n",
    "wordList = wordList[wordList.tangram == 'A']\n",
    "wordList = wordList[wordList.roundNum == 1]\n",
    "\n",
    "wordList\n",
    "\n",
    "\n",
    "partOfSpeechList = test2[['roundNum', 'tangram', 'numWords', 'NNnum', 'VBnum', 'DTnum', 'PRPnum', 'INnum', 'TOnum', 'RBnum']]\n",
    "partOfSpeechList.to_csv(\"partOfSpeechList.csv\")\n",
    "partOfSpeechList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Word total difference among tangrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = ['A','B','C','D','E','F','G','H']\n",
    "N = len(x)\n",
    "y = range(N)\n",
    "width = 1/1.5\n",
    "#plt.bar(x, y, width, color=\"blue\")\n",
    "\n",
    "\n",
    "\n",
    "#fig = plt.gcf()\n",
    "#currently not working. Next task is figure out another thing an AI model would need to play this game.\n",
    "#email Robert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tanDiffs = test2.copy()\n",
    "tanDiffs = tanDiffs.groupby(['tangram']).sum()\n",
    "\n",
    "tans = tanDiffs.loc['A': 'K', 'numWords': 'numWords']\n",
    "tans2 = tans['numWords'].tolist()\n",
    "\n",
    "y = tans2\n",
    "x = ['A','B','C','D','E','F','G','H','I','J','K']\n",
    "width = 1/1.5\n",
    "#plt.bar(x, y, width, color=\"blue\")\n",
    "\n",
    "#fig = plt.gcf()\n",
    "#plot_url = py.plot_mpl(fig, filename='mpl-basic-bar')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NN vs. VB over each round for a tangram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#look at specific tangram if desirable\n",
    "test3 = test2.copy()\n",
    "#test3 = test3[test3.tangram == \"A\"]\n",
    "\n",
    "\n",
    "#groupby tangram and roundNum\n",
    "wordNums = test3.groupby(['tangram', 'roundNum']).sum()\n",
    "\n",
    "\n",
    "#PLOT NN parts of speech\n",
    "\n",
    "pork_NN_A = wordNums.loc['A': 'A', 'NNnum': 'NNnum']\n",
    "df_NN_A = pork_NN_A['NNnum'].tolist()\n",
    "\n",
    "pork_NN_B = wordNums.loc['B': 'B', 'NNnum': 'NNnum']\n",
    "df_NN_B = pork_NN_B['NNnum'].tolist()\n",
    "\n",
    "pork_NN_C = wordNums.loc['C': 'C', 'NNnum': 'NNnum']\n",
    "df_NN_C = pork_NN_C['NNnum'].tolist()\n",
    "\n",
    "pork_NN_D = wordNums.loc['D': 'D', 'NNnum': 'NNnum']\n",
    "df_NN_D = pork_NN_D['NNnum'].tolist()\n",
    "\n",
    "pork_NN_E = wordNums.loc['E': 'E', 'NNnum': 'NNnum']\n",
    "df_NN_E = pork_NN_E['NNnum'].tolist()\n",
    "\n",
    "pork_NN_F = wordNums.loc['F': 'F', 'NNnum': 'NNnum']\n",
    "df_NN_F = pork_NN_F['NNnum'].tolist()\n",
    "\n",
    "pork_NN_G = wordNums.loc['G': 'G', 'NNnum': 'NNnum']\n",
    "df_NN_G = pork_NN_G['NNnum'].tolist()\n",
    "\n",
    "pork_NN_H = wordNums.loc['H': 'H', 'NNnum': 'NNnum']\n",
    "df_NN_H = pork_NN_H['NNnum'].tolist()\n",
    "\n",
    "pork_NN_I = wordNums.loc['I': 'I', 'NNnum': 'NNnum']\n",
    "df_NN_I = pork_NN_I['NNnum'].tolist()\n",
    "\n",
    "pork_NN_J = wordNums.loc['J': 'J', 'NNnum': 'NNnum']\n",
    "df_NN_J = pork_NN_J['NNnum'].tolist()\n",
    "\n",
    "pork_NN_K = wordNums.loc['K': 'K', 'NNnum': 'NNnum']\n",
    "df_NN_K = pork_NN_K['NNnum'].tolist()\n",
    "\n",
    "pork_NN_L = wordNums.loc['L': 'L', 'NNnum': 'NNnum']\n",
    "df_NN_L = pork_NN_L['NNnum'].tolist()\n",
    "\n",
    "#plotting NN\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "rounds = [1,2,3,4,5,6]\n",
    "NN_A = df_NN_A\n",
    "NN_B = df_NN_B\n",
    "NN_C = df_NN_C\n",
    "NN_D = df_NN_D\n",
    "NN_E = df_NN_E\n",
    "NN_F = df_NN_F\n",
    "NN_G = df_NN_G\n",
    "NN_H = df_NN_H\n",
    "NN_I = df_NN_I\n",
    "NN_J = df_NN_J\n",
    "NN_K = df_NN_K\n",
    "NN_L = df_NN_L\n",
    "\n",
    "plt.plot(rounds, NN_A, color='blue')\n",
    "plt.plot(rounds, NN_B, color='blue')\n",
    "plt.plot(rounds, NN_C, color='blue')\n",
    "plt.plot(rounds, NN_D, color='blue')\n",
    "plt.plot(rounds, NN_E, color='blue')\n",
    "plt.plot(rounds, NN_F, color='blue')\n",
    "plt.plot(rounds, NN_G, color='blue')\n",
    "plt.plot(rounds, NN_H, color='blue')\n",
    "plt.plot(rounds, NN_I, color='blue')\n",
    "plt.plot(rounds, NN_J, color='blue')\n",
    "plt.plot(rounds, NN_K, color='blue')\n",
    "\n",
    "\n",
    "#PLOTTING VB\n",
    "\n",
    "pork_VB_A = wordNums.loc['A': 'A', 'VBnum': 'VBnum']\n",
    "df_VB_A = pork_VB_A['VBnum'].tolist()\n",
    "\n",
    "pork_VB_B = wordNums.loc['B': 'B', 'VBnum': 'VBnum']\n",
    "df_VB_B = pork_VB_B['VBnum'].tolist()\n",
    "\n",
    "pork_VB_C = wordNums.loc['C': 'C', 'VBnum': 'VBnum']\n",
    "df_VB_C = pork_VB_C['VBnum'].tolist()\n",
    "\n",
    "pork_VB_D = wordNums.loc['D': 'D', 'VBnum': 'VBnum']\n",
    "df_VB_D = pork_VB_D['VBnum'].tolist()\n",
    "\n",
    "pork_VB_E = wordNums.loc['E': 'E', 'VBnum': 'VBnum']\n",
    "df_VB_E = pork_VB_E['VBnum'].tolist()\n",
    "\n",
    "pork_VB_F = wordNums.loc['F': 'F', 'VBnum': 'VBnum']\n",
    "df_VB_F = pork_VB_F['VBnum'].tolist()\n",
    "\n",
    "pork_VB_G = wordNums.loc['G': 'G', 'VBnum': 'VBnum']\n",
    "df_VB_G = pork_VB_G['VBnum'].tolist()\n",
    "\n",
    "pork_VB_H = wordNums.loc['H': 'H', 'VBnum': 'VBnum']\n",
    "df_VB_H = pork_VB_H['VBnum'].tolist()\n",
    "\n",
    "pork_VB_I = wordNums.loc['I': 'I', 'VBnum': 'VBnum']\n",
    "df_VB_I = pork_VB_I['VBnum'].tolist()\n",
    "\n",
    "pork_VB_J = wordNums.loc['J': 'J', 'VBnum': 'VBnum']\n",
    "df_VB_J = pork_VB_J['VBnum'].tolist()\n",
    "\n",
    "pork_VB_K = wordNums.loc['K': 'K', 'VBnum': 'VBnum']\n",
    "df_VB_K = pork_VB_K['VBnum'].tolist()\n",
    "\n",
    "pork_VB_L = wordNums.loc['L': 'L', 'VBnum': 'VBnum']\n",
    "df_VB_L = pork_VB_L['VBnum'].tolist()\n",
    "\n",
    "#plotting\n",
    "#fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "rounds = [1,2,3,4,5,6]\n",
    "VB_A = df_VB_A\n",
    "VB_B = df_VB_B\n",
    "VB_C = df_VB_C\n",
    "VB_D = df_VB_D\n",
    "VB_E = df_VB_E\n",
    "VB_F = df_VB_F\n",
    "VB_G = df_VB_G\n",
    "VB_H = df_VB_H\n",
    "VB_I = df_VB_I\n",
    "VB_J = df_VB_J\n",
    "VB_K = df_VB_K\n",
    "VB_L = df_VB_L\n",
    "\n",
    "plt.plot(rounds, VB_A, color='red')\n",
    "plt.plot(rounds, VB_B, color='red')\n",
    "plt.plot(rounds, VB_C, color='red')\n",
    "plt.plot(rounds, VB_D, color='red')\n",
    "plt.plot(rounds, VB_E, color='red')\n",
    "plt.plot(rounds, VB_F, color='red')\n",
    "plt.plot(rounds, VB_G, color='red')\n",
    "plt.plot(rounds, VB_H, color='red')\n",
    "plt.plot(rounds, VB_I, color='red')\n",
    "plt.plot(rounds, VB_J, color='red')\n",
    "plt.plot(rounds, VB_K, color='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Graphing POS/totalWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordNums2 = wordNums.copy()\n",
    "#calculate ratio of NN POS/total numWords\n",
    "wordNums2['NNnumRat'] = wordNums2['NNnum']/wordNums2['numWords']\n",
    "#calculate ratio of VB POS/total numWords\n",
    "wordNums2['VBnumRat'] = wordNums2['VBnum']/wordNums2['numWords']\n",
    "\n",
    "#RENAMING\n",
    "#to make my life easier...so I can copy and past above code, I am changing the column names \n",
    "#NNnum will become NNraw and VBnum will become VBraw\n",
    "wordNums2=wordNums2.rename(columns = {'NNnum':'NNraw'})\n",
    "wordNums2=wordNums2.rename(columns = {'VBnum':'VBraw'})\n",
    "\n",
    "#NNnumRat will be NNnum and VBnumRat will be VBnum\n",
    "wordNums2=wordNums2.rename(columns = {'NNnumRat':'NNnum'})\n",
    "wordNums2=wordNums2.rename(columns = {'VBnumRat':'VBnum'})\n",
    "\n",
    "#now, I'm pulling the code from above to graph the ratio of NNnum and VBnum over rounds 1-6\n",
    "\n",
    "#PLOT NN parts of speech\n",
    "\n",
    "pork_NN_A = wordNums2.loc['A': 'A', 'NNnum': 'NNnum']\n",
    "df_NN_A = pork_NN_A['NNnum'].tolist()\n",
    "\n",
    "pork_NN_B = wordNums2.loc['B': 'B', 'NNnum': 'NNnum']\n",
    "df_NN_B = pork_NN_B['NNnum'].tolist()\n",
    "\n",
    "pork_NN_C = wordNums2.loc['C': 'C', 'NNnum': 'NNnum']\n",
    "df_NN_C = pork_NN_C['NNnum'].tolist()\n",
    "\n",
    "pork_NN_D = wordNums2.loc['D': 'D', 'NNnum': 'NNnum']\n",
    "df_NN_D = pork_NN_D['NNnum'].tolist()\n",
    "\n",
    "pork_NN_E = wordNums2.loc['E': 'E', 'NNnum': 'NNnum']\n",
    "df_NN_E = pork_NN_E['NNnum'].tolist()\n",
    "\n",
    "pork_NN_F = wordNums2.loc['F': 'F', 'NNnum': 'NNnum']\n",
    "df_NN_F = pork_NN_F['NNnum'].tolist()\n",
    "\n",
    "pork_NN_G = wordNums2.loc['G': 'G', 'NNnum': 'NNnum']\n",
    "df_NN_G = pork_NN_G['NNnum'].tolist()\n",
    "\n",
    "pork_NN_H = wordNums2.loc['H': 'H', 'NNnum': 'NNnum']\n",
    "df_NN_H = pork_NN_H['NNnum'].tolist()\n",
    "\n",
    "pork_NN_I = wordNums2.loc['I': 'I', 'NNnum': 'NNnum']\n",
    "df_NN_I = pork_NN_I['NNnum'].tolist()\n",
    "\n",
    "pork_NN_J = wordNums2.loc['J': 'J', 'NNnum': 'NNnum']\n",
    "df_NN_J = pork_NN_J['NNnum'].tolist()\n",
    "\n",
    "pork_NN_K = wordNums2.loc['K': 'K', 'NNnum': 'NNnum']\n",
    "df_NN_K = pork_NN_K['NNnum'].tolist()\n",
    "\n",
    "pork_NN_L = wordNums2.loc['L': 'L', 'NNnum': 'NNnum']\n",
    "df_NN_L = pork_NN_L['NNnum'].tolist()\n",
    "\n",
    "#plotting NN\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "rounds = [1,2,3,4,5,6]\n",
    "NN_A = df_NN_A\n",
    "NN_B = df_NN_B\n",
    "NN_C = df_NN_C\n",
    "NN_D = df_NN_D\n",
    "NN_E = df_NN_E\n",
    "NN_F = df_NN_F\n",
    "NN_G = df_NN_G\n",
    "NN_H = df_NN_H\n",
    "NN_I = df_NN_I\n",
    "NN_J = df_NN_J\n",
    "NN_K = df_NN_K\n",
    "NN_L = df_NN_L\n",
    "\n",
    "plt.plot(rounds, NN_A, color='blue')\n",
    "plt.plot(rounds, NN_B, color='blue')\n",
    "plt.plot(rounds, NN_C, color='blue')\n",
    "plt.plot(rounds, NN_D, color='blue')\n",
    "plt.plot(rounds, NN_E, color='blue')\n",
    "plt.plot(rounds, NN_F, color='blue')\n",
    "plt.plot(rounds, NN_G, color='blue')\n",
    "plt.plot(rounds, NN_H, color='blue')\n",
    "plt.plot(rounds, NN_I, color='blue')\n",
    "plt.plot(rounds, NN_J, color='blue')\n",
    "plt.plot(rounds, NN_K, color='blue')\n",
    "\n",
    "\n",
    "#PLOTTING VB\n",
    "\n",
    "pork_VB_A = wordNums2.loc['A': 'A', 'VBnum': 'VBnum']\n",
    "df_VB_A = pork_VB_A['VBnum'].tolist()\n",
    "\n",
    "pork_VB_B = wordNums2.loc['B': 'B', 'VBnum': 'VBnum']\n",
    "df_VB_B = pork_VB_B['VBnum'].tolist()\n",
    "\n",
    "pork_VB_C = wordNums2.loc['C': 'C', 'VBnum': 'VBnum']\n",
    "df_VB_C = pork_VB_C['VBnum'].tolist()\n",
    "\n",
    "pork_VB_D = wordNums2.loc['D': 'D', 'VBnum': 'VBnum']\n",
    "df_VB_D = pork_VB_D['VBnum'].tolist()\n",
    "\n",
    "pork_VB_E = wordNums2.loc['E': 'E', 'VBnum': 'VBnum']\n",
    "df_VB_E = pork_VB_E['VBnum'].tolist()\n",
    "\n",
    "pork_VB_F = wordNums2.loc['F': 'F', 'VBnum': 'VBnum']\n",
    "df_VB_F = pork_VB_F['VBnum'].tolist()\n",
    "\n",
    "pork_VB_G = wordNums2.loc['G': 'G', 'VBnum': 'VBnum']\n",
    "df_VB_G = pork_VB_G['VBnum'].tolist()\n",
    "\n",
    "pork_VB_H = wordNums2.loc['H': 'H', 'VBnum': 'VBnum']\n",
    "df_VB_H = pork_VB_H['VBnum'].tolist()\n",
    "\n",
    "pork_VB_I = wordNums2.loc['I': 'I', 'VBnum': 'VBnum']\n",
    "df_VB_I = pork_VB_I['VBnum'].tolist()\n",
    "\n",
    "pork_VB_J = wordNums2.loc['J': 'J', 'VBnum': 'VBnum']\n",
    "df_VB_J = pork_VB_J['VBnum'].tolist()\n",
    "\n",
    "pork_VB_K = wordNums2.loc['K': 'K', 'VBnum': 'VBnum']\n",
    "df_VB_K = pork_VB_K['VBnum'].tolist()\n",
    "\n",
    "pork_VB_L = wordNums2.loc['L': 'L', 'VBnum': 'VBnum']\n",
    "df_VB_L = pork_VB_L['VBnum'].tolist()\n",
    "\n",
    "#plotting\n",
    "#fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "rounds = [1,2,3,4,5,6]\n",
    "VB_A = df_VB_A\n",
    "VB_B = df_VB_B\n",
    "VB_C = df_VB_C\n",
    "VB_D = df_VB_D\n",
    "VB_E = df_VB_E\n",
    "VB_F = df_VB_F\n",
    "VB_G = df_VB_G\n",
    "VB_H = df_VB_H\n",
    "VB_I = df_VB_I\n",
    "VB_J = df_VB_J\n",
    "VB_K = df_VB_K\n",
    "VB_L = df_VB_L\n",
    "\n",
    "plt.plot(rounds, VB_A, color='red')\n",
    "plt.plot(rounds, VB_B, color='red')\n",
    "plt.plot(rounds, VB_C, color='red')\n",
    "plt.plot(rounds, VB_D, color='red')\n",
    "plt.plot(rounds, VB_E, color='red')\n",
    "plt.plot(rounds, VB_F, color='red')\n",
    "plt.plot(rounds, VB_G, color='red')\n",
    "plt.plot(rounds, VB_H, color='red')\n",
    "plt.plot(rounds, VB_I, color='red')\n",
    "plt.plot(rounds, VB_J, color='red')\n",
    "plt.plot(rounds, VB_K, color='red')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Testing word count function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = {'NN': [('guy', 1), ('hi', 13)], 'NNS': [('arms', 1)]}\n",
    "text.values()[1][1][1]\n",
    "list1 = [('guy', 1), ('hi', 1), ('yoyo', 20)]\n",
    "\n",
    "#counts up the numbers associated with each word in a list\n",
    "def total(l):\n",
    "    count = 0\n",
    "    length = len(l)\n",
    "    for i in range(0,length):\n",
    "        num = l[i][1]\n",
    "        print num\n",
    "        count += num\n",
    "        #print count\n",
    "    else: \n",
    "        return count\n",
    "#count up the numbers associated with each word in list of lists (need .values() for dict)\n",
    "def totalAll(l):\n",
    "    count = 0\n",
    "    length = len(l)\n",
    "    for i in range(0,length):\n",
    "        num = total(l[i])\n",
    "        count += num\n",
    "    else:\n",
    "        return count\n",
    "    \n",
    "#totalAll(text.values())\n",
    "\n",
    "#text.values()[1][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.height', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "#given a tag (like NN) find all the words tagged with that and their frequency\n",
    "def findtags(tag_prefix, tagged_text):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\n",
    "                                  if tag.startswith(tag_prefix))\n",
    "    return dict((tag, cfd[tag].most_common(5)) for tag in cfd.conditions())\n",
    "\n",
    "#tokenize contents and look at one tangram at a time and groupby gameid, tangram, roundNum, contents\n",
    "test1['tokens'] = [[word for word in nltk.word_tokenize(sentence.lower()) if word.isalpha()] for sentence in test1['contents']]\n",
    "test2 = test1.copy()\n",
    "del test2['time']\n",
    "\n",
    "#tag part of speech for each token\n",
    "test2['pos'] = [nltk.pos_tag(rowTokens) for rowTokens in test2['tokens']]\n",
    "\n",
    "\n",
    "for g in ['1903-d']:\n",
    "    for i in ['1', '2', '3', '4', '5', '6']:\n",
    "        for t in ['A']:\n",
    "            test2 = test2[(test2.tangram == t) & (test2.gameid == g) & (test2.roundNum == i)]\n",
    "            #test2.groupby(['gameid', 'tangram', 'roundNum', 'contents']).sum()\n",
    "            #print(test2)\n",
    "\n",
    "            #create part of speech column\n",
    "            test2['pos'] = [nltk.pos_tag(rowTokens) for rowTokens in test2['tokens']]\n",
    "\n",
    "            tags = test2['pos']\n",
    "            #turn tags from series into list and flatten\n",
    "            tags.tolist()\n",
    "            tagsFlat = [item for sublist in tags for item in sublist]\n",
    "            #tagsFlat\n",
    "\n",
    "            #look at frequency of parts of speech \n",
    "            tags_fd = nltk.FreqDist(tag for (word, tag) in tagsFlat)\n",
    "            tags_fd.most_common()\n",
    "\n",
    "            #locate all words tagged with NN and display their frequency\n",
    "            tagdictVB = findtags('VB', tagsFlat)\n",
    "            tagdictNN = findtags('NN', tagsFlat)\n",
    "            \n",
    "\n",
    "            #for tag in sorted(tagdict): print(tag, tagdict[tag])\n",
    "            #print(g, i, t, tagdictVB)\n",
    "            #print(g, i, t, tagdictNN)\n",
    "            print(tagsFlat)\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(\"All done!\")\n",
    "\n",
    "\n",
    "#CC, VB, DT, NN, CD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Plotting word frequency distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged = pd.read_csv('/Users/nickimaslan/Desktop/convention_project/tangrams_replication/data/annotated_names/merged.csv')\n",
    "merged.drop(['gameid','time'], axis=1)\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def tokenize(listOfStrings):\n",
    "    mergedStr = []\n",
    "    for wordStr in listOfStrings :   \n",
    "        potato = nltk.word_tokenize(wordStr)\n",
    "        mergedStr.append(potato)\n",
    "    flat = [item for sublist in mergedStr for item in sublist]\n",
    "    return flat\n",
    "#     return list(chain.from_iterable(mergedStr))\n",
    "\n",
    "def tangram(merged, tangram, roundNum ):   ##select tangram and round you want to look at\n",
    "    merged.drop(['gameid','time'], axis=1)\n",
    "    tanMerged = merged[merged['tangram'] == tangram]\n",
    "    tanRound = tanMerged[tanMerged['roundNum'] == roundNum]\n",
    "    return tanRound\n",
    "\n",
    "def tokTan(dataframe):       ##will tokenize the contents grouped by roundNum\n",
    "    wordsCountedC1 = dataframe.groupby(['roundNum'])['contents'].aggregate(tokenize)\n",
    "    return wordsCountedC1\n",
    "\n",
    "def cleanup(listofStrings):  ##only will do one list at a time\n",
    "    listofStrings = [w for w in listofStrings if w not in stopwords]\n",
    "    listofStrings = [w for w in listofStrings if w.isalpha()]\n",
    "    listofStrings = [w for w in listofStrings if len(w) > 2]\n",
    "    listofStrings = [w.lower() for w in listofStrings if w.isalpha()] \n",
    "    listofStrings = [w for w in listofStrings if w not in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', 'the', 'like', 'either' 'ready', 'yeah' 'really,' 'ok', 'looks', 'okay', 'one', 'got', 'go']]\n",
    "    return listofStrings\n",
    "\n",
    "##example with tangram C on round1\n",
    "tangramCr1 = tangram(merged, 'C', '1')\n",
    "tokCr1 = tokTan(tangramCr1)\n",
    "cleanCr1 = cleanup(tokCr1[0])\n",
    "cleanCr1\n",
    "\n",
    "##plot the frequency distribution\n",
    "\n",
    "wordsCounted = merged.groupby(['roundNum'])['contents'].aggregate(tokenize)    #list of words in each round\n",
    "cleaned1 = cleanup(wordsCounted[0])  # cleaned up list of words in round1\n",
    "cleaned2 = cleanup(wordsCounted[1])\n",
    "cleaned3 = cleanup(wordsCounted[2])\n",
    "cleaned4 = cleanup(wordsCounted[3])\n",
    "cleaned5 = cleanup(wordsCounted[4])\n",
    "cleaned6 = cleanup(wordsCounted[5])\n",
    "\n",
    "c = 0\n",
    "while c < 6:\n",
    "    cleanWords = cleanup(wordsCounted[c])\n",
    "    c = c + 1\n",
    "\n",
    "#cleanWords\n",
    "#cleaned2\n",
    "\n",
    "#wordsCounted\n",
    "#fdist1 = nltk.FreqDist(cleaned)\n",
    "#fdist1.plot(30, cumulative=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tangram C vs G graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged = pd.read_csv('/Users/nickimaslan/Desktop/convention_project/tangrams_replication/data/annotated_names/merged.csv')\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def countWords(listOfStrings):\n",
    "    wordCount = 0\n",
    "    for wordStr in listOfStrings :   \n",
    "        potato = nltk.word_tokenize(wordStr) # tokenize it (returns a list of words)\n",
    "        cleanPotato = cleanup(potato)\n",
    "        length = len(potato)   # get length of token list\n",
    "        wordCount = wordCount + length # add that number to wordCount\n",
    "    return wordCount\n",
    "\n",
    "def cleanup(aStr) :\n",
    "    listofStrings = [w for w in aStr if w not in stopwords]\n",
    "    listofStrings = [w for w in listofStrings if w.isalpha()]\n",
    "    listofStrings = [w for w in listofStrings if len(w) > 2]\n",
    "    listofStrings = [w.lower() for w in listofStrings if w.isalpha()] \n",
    "    listofStrings = [w for w in listofStrings if w not in ['like', 'either' 'ready', 'yeah' 'really,' 'ok', 'looks', 'okay', 'one', 'got', 'go']]\n",
    "    return listofStrings\n",
    "\n",
    "tanC = merged[merged['tangram'] == 'C']\n",
    "tanG = merged[merged['tangram'] == 'G']\n",
    "\n",
    "def getMean(dataframe):\n",
    "    meanList = []\n",
    "    for roundNumber in [1,2,3,4,5,6] :\n",
    "        mergeByRound = dataframe[dataframe['roundNum'] == '%d' %roundNumber]\n",
    "        wordsCounted = mergeByRound.groupby(['roundNum'])['contents'].aggregate(countWords)\n",
    "        wordsPerRound = wordsCounted.apply(lambda x: x/(24))\n",
    "        wordMean = wordsPerRound.mean()\n",
    "        meanList.append(wordMean)\n",
    "    return meanList\n",
    "\n",
    "print(getMean(tanC))\n",
    "print(getMean(tanG))\n",
    "# print(tanC)\n",
    "# print(tanG)\n",
    "\n",
    "\n",
    "\n",
    "def getStDev(dataframe):\n",
    "    stdList = []\n",
    "    for roundNumber in [1,2,3,4,5,6] :\n",
    "        mergeByRound = dataframe[dataframe['roundNum'] == '%d' %roundNumber]\n",
    "        wordsCounted = mergeByRound.groupby(['roundNum','gameid'])['contents'].aggregate(countWords)\n",
    "        wordsPerRound = wordsCounted.apply(lambda x: x/(1))\n",
    "        std = wordsPerRound.std()\n",
    "        stdList.append(std)\n",
    "    return stdList\n",
    "\n",
    "\n",
    "\n",
    "##df for tangram C\n",
    "tanC = merged[merged['tangram'] == 'C']\n",
    "wordsCountedC = tanC.groupby(['roundNum','gameid'])['contents'].aggregate(countWords)\n",
    "meanC = getMean(tanC)\n",
    "stErrorC = getStDev(tanC)/np.sqrt(24)\n",
    "print(meanC)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# ##df for tangram G\n",
    "tanG = merged[merged['tangram'] == 'G']\n",
    "wordsCountedG = tanG.groupby(['roundNum', 'gameid'])['contents'].aggregate(countWords)\n",
    "meanG = getMean(tanG)\n",
    "stErrorG = getStDev(tanG)/np.sqrt(24)\n",
    "stErrorG\n",
    "print(meanG)\n",
    "\n",
    "##plot it\n",
    "##data to be plotted\n",
    "# wordsPerRound = wordsCounted.apply(lambda x: x/(12*24))\n",
    "rounds = [1,2,3,4,5,6]\n",
    "\n",
    "##error data\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "\n",
    "##plotting\n",
    "# fig = plt.figure(figsize=(6, 6))\n",
    "# axes = fig.add_subplot(111)\n",
    "plt.plot(rounds, meanG, color='red')\n",
    "plt.plot(rounds, meanC, color='blue')\n",
    "# \n",
    "##plot error bars\n",
    "plt.errorbar(rounds,meanG,yerr=stErrorG, linestyle=\"None\", color=\"red\")\n",
    "plt.errorbar(rounds,meanC,yerr=stErrorC, linestyle=\"None\", color=\"blue\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#configure x and y axes\n",
    "plt.ylim([0,40])\n",
    "plt.xlim([0,7])\n",
    "plt.title('Tangram C vs. G words per round', size=15)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Trials', size=14)\n",
    "plt.ylabel('Average amount of words players used', size=14)\n",
    "\n",
    "##save plot\n",
    "plt.savefig(\"/Users/nickimaslan/Desktop/GvsCTangrams.png\", bbox_inches='tight')\n",
    "\n",
    "##show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg Director word count for each tangram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged = pd.read_csv('/Users/nickimaslan/Desktop/convention_project/tangrams_replication/data/annotated_names/merged.csv')\n",
    "from itertools import chain\n",
    "def countWords(listOfStrings):\n",
    "    wordCount = 0\n",
    "    for wordStr in listOfStrings :   \n",
    "        potato = nltk.word_tokenize(wordStr) # tokenize it (returns a list of words)\n",
    "        length = len(potato)   # get length of token list\n",
    "        wordCount = wordCount + length # add that number to wordCount\n",
    "    return wordCount\n",
    "        \n",
    "# merged.groupby(['tangram'])['roundNum'].apply(plus1)\n",
    "merged = merged[merged['sender'] == 'director']\n",
    "merged = merged[merged['tangram'] != '0']\n",
    "merged = merged[merged['tangram'] != '10']\n",
    "merged = merged[merged['tangram'] != ':']\n",
    "\n",
    "def getStDev(dataframe):\n",
    "    stdList = []\n",
    "    for roundNumber in [1,2,3,4,5,6] :\n",
    "        mergeByRound = merged[merged['roundNum'] == '%d' %roundNumber]\n",
    "        wordsCounted = mergeByRound.groupby(['roundNum','gameid'])['contents'].aggregate(countWords)\n",
    "        wordsPerRound = wordsCounted.apply(lambda x: x/(12))\n",
    "        std = wordsPerRound.std()\n",
    "        stdList.append(std)\n",
    "    return stdList\n",
    "\n",
    "error = np.sqrt(24)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "wordsCounted = merged.groupby(['roundNum'])['contents'].aggregate(countWords)\n",
    "\n",
    "##data to be plotted\n",
    "wordsPerRound = wordsCounted.apply(lambda x: x/(12*24))\n",
    "rounds = [1,2,3,4,5,6]\n",
    "\n",
    "##error data\n",
    "stdErrorList = getStDev(merged)/error\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "\n",
    "##plotting\n",
    "# fig = plt.figure(figsize=(6, 6))\n",
    "# axes = fig.add_subplot(111)\n",
    "plt.plot(rounds, wordsPerRound)\n",
    "\n",
    "##plot error bars\n",
    "plt.errorbar(rounds,wordsPerRound,yerr=stdList, linestyle=\"None\", color=\"green\")\n",
    "\n",
    "#configure x and y axes\n",
    "plt.ylim([0,20])\n",
    "plt.xlim([0,7])\n",
    "plt.title('Avg director word count for each tangram', size=15)\n",
    "plt.grid(True)\n",
    "plt.xlabel('trials', size=14)\n",
    "plt.ylabel('mean number words (by director) per figure', size=14)\n",
    "\n",
    "##save plot\n",
    "plt.savefig(\"/Users/nickimaslan/Desktop/avgWordsTallFont.png\", bbox_inches='tight')\n",
    "\n",
    "##show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged = pd.read_csv('/Users/nickimaslan/Desktop/convention_project/tangrams_replication/data/annotated_names/merged.csv')\n",
    "# merged.ix[0:, ['contents', 'tangram']]\n",
    "tangramMerge = merged[merged['tangram'] != '0']\n",
    "tangram = merged[merged['tangram'] == 'G']\n",
    "tangramRound = tangram[tangram['roundNum'] == '6']\n",
    "contents = tangramRound.ix[0:, ['contents']]\n",
    "contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Score Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_test = pd.read_csv('/Users/nickimaslan/Desktop/convention_project/tangrams_replication/data/good_dropObj/0215-4.csv')\n",
    "score1 = score_test[[' roundNum', ' score']]\n",
    "#score_group = score1.groupby('roundNum')\n",
    "score1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
