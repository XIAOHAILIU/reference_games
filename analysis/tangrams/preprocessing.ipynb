{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import lots of stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pylab as pyl\n",
    "import nltk as nltk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "%matplotlib inline\n",
    "#enable longer display\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import annotated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d_raw = pd.read_csv('../../data/tangrams/old/oldTangrams.csv')\n",
    "\n",
    "# Drop time column\n",
    "d = (d_raw\n",
    "    .copy()\n",
    "    .drop('time', 1)\n",
    "    .query('tangram != \"0\"')\n",
    "    .query('tangram != \"*\"'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d['tokens'] = [[word for word in nltk.word_tokenize(sentence.lower()) if word.isalpha()]\n",
    "               for sentence in d['contents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get number of words used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d['numWords'] = [pd.value_counts(words).sum() for words in d['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 1: Generate file for POS analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d['pos'] = [[pos for (key, pos) in nltk.pos_tag(rowTokens, tagset = 'universal')] \n",
    "            for rowTokens in d['tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all unique POS labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posSet = set({})\n",
    "for row in d['pos'] :\n",
    "    for pos in row :\n",
    "        posSet.add(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get counts for each POS label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for pos in posSet :\n",
    "    colName = pos + \"num\"\n",
    "    d[colName] = [posList.count(pos) for posList in d['pos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to csv for plotting in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(d.drop([\"pos\", \"contents\", \"tokens\"], 1)\n",
    " .to_csv(\"posTagged.csv\", index = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 2: Calculate indicator words for tangrams/rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, get list of words in first round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter down to first round\n",
    "d_round1 = d[d['roundNum'] == 1]\n",
    "\n",
    "# Pull out all tokens and collapse into count dict\n",
    "tokenDict = Counter([item for sublist in d_round1['tokens'].tolist()\n",
    "                     for item in sublist])\n",
    "\n",
    "# Pull out all words that occur more than once\n",
    "wordList = [word for (word,count) in tokenDict.items() if count > 1]\n",
    "print(wordList[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all game ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gameidList = pd.unique(d.gameid.ravel()).tolist()\n",
    "print(gameidList[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of all tangram names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tangramList = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
    "print(tangramList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to select words & counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getWordCounts(df, gameid, roundNum, tangram = None) :\n",
    "    roundCond = 'roundNum == ' + roundNum\n",
    "    gameidCond = 'gameid == \"' + gameid + '\"'\n",
    "    if(tangram is not None) :\n",
    "        tangramCond = 'tangram == \"' + tangram + '\"'\n",
    "        cond = \" and \".join((roundCond, gameidCond, tangramCond))\n",
    "    else :\n",
    "        cond = \" and \".join((roundCond, gameidCond))\n",
    "    relevantRow = df.query(cond)\n",
    "    return Counter([item for sublist in relevantRow['tokens'].tolist() \n",
    "                    for item in sublist])\n",
    "\n",
    "#creates mini dataframe that grabs the words used in round n for a given tangram and gameid\n",
    "def selectTangramRoundWords(df, tangram, roundNum, gameid):\n",
    "    wordCounts = getWordCounts(df, gameid, roundNum, tangram)\n",
    "    return wordCounts.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to compute PMIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that merging is really costly -- if we need to speed it up, this might be the first target. Can also vectorize the log operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns a table with the all words above 0 PMI and their counts for a given tangram\n",
    "#calculate the probability for words given tangram A ------ p(x|y)\n",
    "def makeMyPMI(df, tangram, roundNum, gameid, totals):\n",
    "\n",
    "    # count words w/in tangram\n",
    "    tangramCounts = getWordCounts(df, gameid, roundNum, tangram)\n",
    "\n",
    "    #total number of words \n",
    "    tangramNumWords = (1 if sum(tangramCounts.values()) == 0 \n",
    "                       else sum(tangramCounts.values()))\n",
    "\n",
    "    #dataframe to compare \n",
    "    indicatorDF = pd.merge(pd.DataFrame(tangramCounts.items(), columns=['word', 'count']),\n",
    "                           pd.DataFrame(totals[\"counts\"].items(), columns=['word', 'totalCount']),\n",
    "                           on='word', how = 'inner')\n",
    "\n",
    "    #calculate PMI without log first. Having trouble with float issues. \n",
    "    indicatorDF['roughPMI'] = ((indicatorDF['count']/tangramNumWords)\n",
    "                                / (indicatorDF['totalCount']/totals[\"numWords\"]))\n",
    "    indicatorDF['logPMI'] = [math.log10(num) for num in indicatorDF['roughPMI']]\n",
    "    \n",
    "    #remove column rough PMI\n",
    "    indicatorDF = indicatorDF.drop('roughPMI', 1)\n",
    "    \n",
    "    return indicatorDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out PMIs & matching rates for all words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we do a sloppy optimization by only computing total counts once and only when necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def memoize(d, gameid, counts) : \n",
    "    if \"counts\" not in counts : \n",
    "        counts[\"counts\"] = getWordCounts(d, gameid, \"1\")\n",
    "        counts[\"numWords\"] = float(sum(counts[\"counts\"].values()))\n",
    "        return counts\n",
    "    else \n",
    "        return counts\n",
    "\n",
    "with open('matchAndPMI.csv', 'ab') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['word', 'match', 'pmi', 'total'])\n",
    "    for word in wordList :\n",
    "        print(word)\n",
    "        pmi = 0\n",
    "        match = 0\n",
    "        total = 0\n",
    "        for gameid in gameidList:  \n",
    "            memoizedCounts = {}\n",
    "            for tangram in tangramList:\n",
    "                memoizedCounts = memoize(d, gameid, memoizedCounts)\n",
    "                round1WordList = selectTangramRoundWords(d, tangram, \"1\", gameid)\n",
    "                total = total + 1 if word in round1WordList else total\n",
    "                if word in round1WordList :\n",
    "                    PMI_df = makeMyPMI(d, tangram, \"1\", gameid, memoizedCounts)\n",
    "                    pmi = pmi + PMI_df[PMI_df['word'] == word]['logPMI'].tolist()[0]\n",
    "                    round6WordList = selectTangramRoundWords(d, tangram, \"6\", gameid)\n",
    "                    match = (match + 1 if (word in round1WordList and word in round6WordList)\n",
    "                             else match)\n",
    "        writer.writerow([word, float(match) / float(total), pmi/total, total])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bootstrap analysis (might want to move to R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grab words with highestPMI for a given tangram/gameid\n",
    "def highestPMIWords(d, tangram, roundNum, gameid):\n",
    "    allTangramCounts = {}\n",
    "    allTangramCounts['counts'] = getWordCounts(d, gameid, \"1\")\n",
    "    allTangramCounts['numWords'] = float(sum(allTangramCounts[\"counts\"].values()))\n",
    "\n",
    "    PMIdf = makeMyPMI(d, tangram, roundNum, gameid, allTangramCounts)\n",
    "    #if PMIdf has words, pull out max values, it is empty return it as is\n",
    "    if len(PMIdf.index) > 0:\n",
    "        PMI_values = PMIdf.logPMI.unique()\n",
    "        maxPMI = PMI_values.max()\n",
    "        PMIdf = PMIdf.loc[PMIdf['logPMI'] == maxPMI]\n",
    "        PMIdfword = PMIdf['word']\n",
    "        return PMIdfword.tolist()\n",
    "    else: \n",
    "        return PMIdf\n",
    "\n",
    "numSamples = 100\n",
    "with open('PMIbootstrap.csv', 'wb') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['tangram', 'gameid', 'numCandidates', 'match', 'highest'])\n",
    "    for gameid in gameidList :\n",
    "        for tangram in tangramList :\n",
    "            round1Words = selectTangramRoundWords(d, tangram, \"1\", gameid)\n",
    "            if len(round1Words) > 0:\n",
    "                # First, write highest PMI match\n",
    "                highPMIWords = highestPMIWords(d, tangram, \"1\", gameid)\n",
    "                round6Words = selectTangramRoundWords(d, tangram, \"6\", gameid)\n",
    "                match = np.mean([1 if word in round6Words else 0 for word in highPMIWords ])\n",
    "                writer.writerow([tangram, gameid, len(highPMIWords), match, \"highest\"])\n",
    "\n",
    "                # Next, take a bunch of null samples\n",
    "                for i in range(numSamples) :\n",
    "                    randomWord = np.random.choice(round1Words)\n",
    "                    match = np.mean([1 if randomWord in round6Words else 0])\n",
    "                    writer.writerow([tangram, gameid, 1, match, \"null\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
